{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Causal Structure Learning from Data\n",
    "\n",
    "In the previous lessons, we saw that causal inference aims to answer questions involving cause and effect. Specifically, we saw how Directed Acyclic Graphs (DAGs) could be used to incorporate our prior knowledge domain and effectively visualize the causal relationships in a clear-cut way.\n",
    "\n",
    "DAGs represent causal structure by showing relationship between causes and effects. A DAG is a special kind of graph where all edges are directed (information flow is in one direction) and no cycles exist (information that leaves a vertex cannot return to it). The vertices (nodes) in a causal DAG represent variables, and edges (arrows) represent causation, where a variable is directly caused by its parents.\n",
    "\n",
    "However, often in the real world, we do not know which variable causes the other. \n",
    "\n",
    "**But how can we create a DAG?**\n",
    "- Sometimes, we have prior knowledge, and we can use it to build a causal model\n",
    "- Other times, we have limited knowledge and we want to estimate/retrieve the causal model from some data we have \n",
    "\n",
    "**With structure learning, we want to determine the structure of the graph that best captures the causal dependencies between the variables in the data set.** \n",
    "In other words, given a dataset, we derive a causal model that describes it.\n",
    "\n",
    "\n",
    "## How can we estimate the causal structure from a dataset?\n",
    "\n",
    "Unfortunately, there is no standard recipe for that, and that's why causal inference is generally challenging. \n",
    "Causal discovery is an example of an inverse problem. \n",
    "However, there are some techniques available, and here we are going to sketch the most common ones and key ideas.\n",
    "The usual approach to solving inverse problems is to **make assumptions** about what you are trying to uncover. This narrows down the possible solutions and hopefully makes the problem solvable. \n",
    "\n",
    "There are four common assumptions made across causal discovery algorithms. A nice discussion of these assumptions can be found in Kalainathan et al (2018) https://arxiv.org/abs/1803.04929\n",
    "\n",
    "- **Acyclicity** — causal structure can be represented by a DAG $G$ (mentioned in [Chapter 3](/lectures/CH-3-Graphical-Causal-Models.ipynb))\n",
    "- **Markov Property** — all nodes are independent of their non-descendants when conditioned on their parents (mentioned in [Chapter 3](/lectures/CH-3-Graphical-Causal-Models.ipynb))\n",
    "- **Faithfulness** — all conditional independences in true underlying distribution $p$ are represented in $G$ \n",
    "- **Sufficiency** — any pair of nodes in $G$ has no common external cause\n",
    "\n",
    "Although these assumptions help narrow down the number of possible causal models, they do not guarantee to build causal models. This is where a few tricks for causal discovery are helpful. A taxonomy of algorithms based on the following tricks is given in the table below.\n",
    "\n",
    "| **TRICK**                             | **ALGORITHM**                                               |\n",
    "|-----------------------------------|---------------------------------------------------------|\n",
    "| **Conditional Independence Testing**  | PC <br> Fast Causal Inference (FCI) <br>  Inductive Causation (IC) |\n",
    "| **Greedy Search on DAG Space**        | Gready Equivalent Search (GES) <br>  Gready Interventional Equivalent Search (GIES) <br> Concave penalized Coordinate Descent with reparametrization (CCDr)                                                        |\n",
    "| **Exploiting Asymmetry**              | Linear Non-Gaussian Acyclic Model (LINGAM) <br>  Nonlinear Additive Noise Models <br> Post_nonlinear Causal Model (PNL) <br> Granger Causality                                                      |\n",
    "| **Hybrid**                            | Structural Agnostic Modeling (SAM) <br> Causal Additive Modeling (CAM) <br> Causal Generative Causal Neural Network (CGNN)                                                       |\n",
    "\n",
    "\n",
    "A comprehensive review of different causal structure search methods is available at:\n",
    "[Review of Causal Discovery Methods Based on Graphical Models](https://www.frontiersin.org/articles/10.3389/fgene.2019.00524/full#:~:text=Causal%20discovery%20aims%20to%20find,process%20or%20the%20sampling%20process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trick 1: Conditional Independence Testing\n",
    "\n",
    "One of these earliest causal discovery algorithms is the PC algorithm named after its authors Peter Spirtes and Clark Glymour. This algorithm (and others like it) use the idea that two statistically independent variables are not causally linked. The PC algorithm is illustrative of this first trick. An outline of the algorithm is given in the figure below (image taken from https://towardsdatascience.com/causal-discovery-6858f9af6dcb). \n",
    "\n",
    "![img](img/ch6/Trick1.png)\n",
    "\n",
    "The first step is to form a fully connected, undirected graph using every variable in the dataset. Next, edges are deleted if the corresponding variables are independent. Then, connected edges undergo conditional independence testing e.g. independence test of bottom and far right node conditioned on middle node in the figure above (step 2).\n",
    "\n",
    "If conditioning on a variable kills the dependence, that variable is added to the Separation set for those two variables. Depending on the size of the graph, conditional independence testing will continue (i.e. condition on more variables) until there are no more candidates for testing.\n",
    "\n",
    "Next, colliders (i.e. $X \\rightarrow Y \\leftarrow Z$) are oriented based on the Separation set of node pairs. Finally, remaining edges are directed based on 2 constraints, 1) no new v-structures and 2) no directed cycles can be formed.\n",
    "\n",
    "\n",
    "### Trick 2: Greedy Search of Graph Space\n",
    "\n",
    "A greedy algorithm is an approach for solving a problem by selecting the best option available at the moment. It doesn't worry whether the current best result will bring the overall optimal result.\n",
    "The algorithm never reverses the earlier decision even if the choice is wrong. It works in a top-down approach.\n",
    "\n",
    "Usually, greedy algorithms are easier to describe and can perform quite good compared to other algorithms.\n",
    "However, greedy searches cannot guarantee an optimal solution. Neverthless, for most problems the space of possible DAGs is so big that finding a true optimal solution is intractable.\n",
    "\n",
    "The Greedy Equivalence Search (GES) algorithm uses this trick. GES starts with an empty graph and iteratively adds directed edges such that the improvement in a model fitness measure (i.e. score) is maximized.\n",
    "\n",
    "### Trick 3: Exploiting Asymmetries\n",
    "\n",
    "As we say, fundamental property of causality is asymmetry. $A$ could cause $B$, but $B$ may not cause $A$. Thus, there are algorithms that leverage this idea to select between causal model candidates, usuallty with respect to time, complexity, and functional.\n",
    "\n",
    "- Time asymmetry is quite natural. It’s the idea that causes happen before effects. This is expoited for example in the Granger causality test. We say that a variable $X$ that evolves over time Granger-causes another evolving variable $Y$ if predictions of the value of $Y$ based on its own past values and on the past values of $X$ are better than predictions of $Y$ based only on $Y$'s own past values.\n",
    "\n",
    "- Complexity asymmetry follows the Occam’s razor principle, that simpler models are better. In other words, if you have handful of candidate models to choose from, this idea says to pick the simplest one. One way of quantifying simplicity (or complexity) is the Kolmogorov Complexity.\n",
    "\n",
    "- Functional asymmetry assumes models that better fit a relationship are better candidates. For example, given two variables $X$ and $Y$, the nonlinear additive noise model (NANM) performs a nonlinear regression between $X$ and $Y$ , e.g. $y = f(x) + n$, where $n$ = noise/residual, in both directions. The model (i.e. causation) is then accepted if the potential cause (e.g. $x$) is independent of the noise term (e.g. $n$).\n",
    "\n",
    "### Trick 4: Hybrid Approaches\n",
    "\n",
    "The last part includes algorithms which differ one fron the other and exploit different assumtpions. For example, Causal Generative Neural Networks (CGNN) try to learn functional\n",
    "causal models from observational data based on generative neural networks.  This area is pretty new and interested readers can find more techincal information in: \n",
    "[CGNN](https://arxiv.org/pdf/1711.08936.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A practical exercise in Python: Shortness of breath disease\n",
    "\n",
    "We will make use of the *bnlearn* library, which is built on top of the extensive *pgmpy* library. *pgmpy* is a pure python implementation for Bayesian Networks with various algorithms for Structure Learning, Parameter Estimation, Approximate (Sampling Based) and Exact inference, and Causal Inference.\n",
    "\n",
    "In this section we will try to analyse patients treatment regarding shortness-of-breath (dyspnoea). The data set is small (few variables) and synthetic from Lauritzen and Spiegelhalter (1988), and is about lung diseases (tuberculosis, lung cancer or bronchitis) and visits to infection areas.\n",
    "\n",
    "*Lauritzen S, Spiegelhalter D (1988). Local Computation with Probabilities on Graphical Structures and their Application to Expert Systems (with discussion). Journal of the Royal Statistical Society*  [link](https://www.jstor.org/stable/2345762?seq=1)\n",
    "\n",
    "**Background:** Shortness-of-breath (*dyspnoea*) may be due to tuberculosis (*tub*), *lung cancer* or *bronchitis*, or none of them, or more than one of them (*either*). A recent visit to infectious areas (*tub_area*) increases the chances of tuberculosis, while smoking (*smoke*) is known to be a risk factor for both lung cancer and bronchitis. The results of a single chest X-ray (*xray*) do not discriminate between lung cancer and tuberculosis, as neither does the presence or absence of dyspnoea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miche\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\miche\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\miche\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pypickle] Pickle file loaded: [c:\\Users\\miche\\Dropbox\\PhD\\Courses\\Causality\\causality-course\\lectures\\data\\smoke_dataset.pkl]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tub_area</th>\n",
       "      <th>tub</th>\n",
       "      <th>smoke</th>\n",
       "      <th>lung</th>\n",
       "      <th>bronc</th>\n",
       "      <th>either</th>\n",
       "      <th>xray</th>\n",
       "      <th>dysp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tub_area  tub  smoke  lung  bronc  either  xray  dysp\n",
       "0             1    1      1     1      1       1     1     1\n",
       "1             1    1      0     0      1       0     0     0\n",
       "2             1    1      1     1      1       1     1     1\n",
       "3             1    1      1     1      1       1     1     1\n",
       "4             1    1      1     1      1       1     1     1\n",
       "...         ...  ...    ...   ...    ...     ...   ...   ...\n",
       "19995         1    1      0     1      1       1     1     1\n",
       "19996         1    1      1     1      1       1     0     1\n",
       "19997         1    1      0     0      0       0     0     0\n",
       "19998         1    1      0     1      1       1     1     1\n",
       "19999         1    1      0     1      1       1     1     1\n",
       "\n",
       "[20000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "import bnlearn as bn\n",
    "df = bn.load(filepath='data/smoke_dataset.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use prior knowledge to assume a causal model and make inference \n",
    "\n",
    "As we saw in the lectures, expert knowledge can be included in bayesian models by using graphs in the form of a Directed Acyclic Graphs. \n",
    "Let's assume that our knowledge about dyspnoea is limited to: smoking is related to lung cancer, smoking is related to bronchitis, and if you have lung or bronchitus we may need an xray examination. Therefore, we create a DAG based on this knowledge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >bayes DAG created.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Pages: 1 -->\n<svg width=\"144pt\" height=\"188pt\"\n viewBox=\"0.00 0.00 144.50 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 140.5,-184 140.5,4 -4,4\"/>\n<!-- smoke -->\n<g id=\"node1\" class=\"node\">\n<title>smoke</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"65\" cy=\"-162\" rx=\"34.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"65\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">smoke</text>\n</g>\n<!-- lung -->\n<g id=\"node2\" class=\"node\">\n<title>lung</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lung</text>\n</g>\n<!-- smoke&#45;&gt;lung -->\n<g id=\"edge1\" class=\"edge\">\n<title>smoke&#45;&gt;lung</title>\n<path fill=\"none\" stroke=\"black\" d=\"M55.99,-144.41C51.45,-136.04 45.84,-125.71 40.77,-116.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"43.79,-114.59 35.94,-107.47 37.64,-117.93 43.79,-114.59\"/>\n</g>\n<!-- bronc -->\n<g id=\"node3\" class=\"node\">\n<title>bronc</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"104\" cy=\"-90\" rx=\"32.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"104\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">bronc</text>\n</g>\n<!-- smoke&#45;&gt;bronc -->\n<g id=\"edge2\" class=\"edge\">\n<title>smoke&#45;&gt;bronc</title>\n<path fill=\"none\" stroke=\"black\" d=\"M74.24,-144.41C78.91,-136.04 84.66,-125.71 89.87,-116.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"93.01,-117.91 94.82,-107.47 86.9,-114.5 93.01,-117.91\"/>\n</g>\n<!-- xray -->\n<g id=\"node4\" class=\"node\">\n<title>xray</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"65\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"65\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">xray</text>\n</g>\n<!-- lung&#45;&gt;xray -->\n<g id=\"edge3\" class=\"edge\">\n<title>lung&#45;&gt;xray</title>\n<path fill=\"none\" stroke=\"black\" d=\"M35.81,-72.76C40.42,-64.28 46.16,-53.71 51.32,-44.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54.54,-45.61 56.23,-35.15 48.39,-42.27 54.54,-45.61\"/>\n</g>\n<!-- bronc&#45;&gt;xray -->\n<g id=\"edge4\" class=\"edge\">\n<title>bronc&#45;&gt;xray</title>\n<path fill=\"none\" stroke=\"black\" d=\"M94.76,-72.41C90.09,-64.04 84.34,-53.71 79.13,-44.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"82.1,-42.5 74.18,-35.47 75.99,-45.91 82.1,-42.5\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x29e86383b50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz as gr\n",
    "\n",
    "edges = [('smoke', 'lung'),\n",
    "         ('smoke', 'bronc'),\n",
    "         ('lung', 'xray'),\n",
    "         ('bronc', 'xray')]\n",
    "\n",
    "# Create the DAG from the edges\n",
    "DAG = bn.make_DAG(edges)\n",
    "\n",
    "# Plot and make sure the arrows are correct.\n",
    "def plot_from_edges(edges):\n",
    "    # plot\n",
    "    g = gr.Digraph()\n",
    "    \n",
    "    for i in range(0, len(edges)):\n",
    "        g.edge(*edges[i])\n",
    "    return g\n",
    "\n",
    "g = plot_from_edges(edges)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have the data set in our dataframe (df), and we have the DAG based on our expert knowledge. \n",
    "We can use parameter learning to learn more about conditional probability distributions (CPDs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Removing columns from dataframe to make consistent with DAG [['tub_area' 'tub' 'either' 'dysp']]\n",
      "[bnlearn] >Parameter learning> Computing parameters using [bayes]\n",
      "[bnlearn] >CPD of smoke:\n",
      "+----------+----------+\n",
      "| smoke(0) | 0.495333 |\n",
      "+----------+----------+\n",
      "| smoke(1) | 0.504667 |\n",
      "+----------+----------+\n",
      "[bnlearn] >CPD of lung:\n",
      "+---------+---------------------+---------------------+\n",
      "| smoke   | smoke(0)            | smoke(1)            |\n",
      "+---------+---------------------+---------------------+\n",
      "| lung(0) | 0.11449721207460103 | 0.03302509907529723 |\n",
      "+---------+---------------------+---------------------+\n",
      "| lung(1) | 0.8855027879253989  | 0.9669749009247027  |\n",
      "+---------+---------------------+---------------------+\n",
      "[bnlearn] >CPD of bronc:\n",
      "+----------+--------------------+--------------------+\n",
      "| smoke    | smoke(0)           | smoke(1)           |\n",
      "+----------+--------------------+--------------------+\n",
      "| bronc(0) | 0.5919054028071524 | 0.3110020758633704 |\n",
      "+----------+--------------------+--------------------+\n",
      "| bronc(1) | 0.4080945971928475 | 0.6889979241366295 |\n",
      "+----------+--------------------+--------------------+\n",
      "[bnlearn] >CPD of xray:\n",
      "+---------+---------------------+-----+---------------------+\n",
      "| bronc   | bronc(0)            | ... | bronc(1)            |\n",
      "+---------+---------------------+-----+---------------------+\n",
      "| lung    | lung(0)             | ... | lung(1)             |\n",
      "+---------+---------------------+-----+---------------------+\n",
      "| xray(0) | 0.8385598141695703  | ... | 0.06883224440968068 |\n",
      "+---------+---------------------+-----+---------------------+\n",
      "| xray(1) | 0.16144018583042974 | ... | 0.9311677555903193  |\n",
      "+---------+---------------------+-----+---------------------+\n"
     ]
    }
   ],
   "source": [
    "# Learn the parameters from data set.\n",
    "# As input we have the DAG without CPDs.\n",
    "DAG = bn.parameter_learning.fit(DAG, df, methodtype='bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPD of smoke:\n",
      "+----------+----------+\n",
      "| smoke(0) | 0.495333 |\n",
      "+----------+----------+\n",
      "| smoke(1) | 0.504667 |\n",
      "+----------+----------+\n",
      "CPD of lung:\n",
      "+---------+---------------------+---------------------+\n",
      "| smoke   | smoke(0)            | smoke(1)            |\n",
      "+---------+---------------------+---------------------+\n",
      "| lung(0) | 0.11449721207460103 | 0.03302509907529723 |\n",
      "+---------+---------------------+---------------------+\n",
      "| lung(1) | 0.8855027879253989  | 0.9669749009247027  |\n",
      "+---------+---------------------+---------------------+\n",
      "CPD of bronc:\n",
      "+----------+--------------------+--------------------+\n",
      "| smoke    | smoke(0)           | smoke(1)           |\n",
      "+----------+--------------------+--------------------+\n",
      "| bronc(0) | 0.5919054028071524 | 0.3110020758633704 |\n",
      "+----------+--------------------+--------------------+\n",
      "| bronc(1) | 0.4080945971928475 | 0.6889979241366295 |\n",
      "+----------+--------------------+--------------------+\n",
      "CPD of xray:\n",
      "+---------+---------------------+-----+---------------------+\n",
      "| bronc   | bronc(0)            | ... | bronc(1)            |\n",
      "+---------+---------------------+-----+---------------------+\n",
      "| lung    | lung(0)             | ... | lung(1)             |\n",
      "+---------+---------------------+-----+---------------------+\n",
      "| xray(0) | 0.8385598141695703  | ... | 0.06883224440968068 |\n",
      "+---------+---------------------+-----+---------------------+\n",
      "| xray(1) | 0.16144018583042974 | ... | 0.9311677555903193  |\n",
      "+---------+---------------------+-----+---------------------+\n",
      "[bnlearn] >Independencies:\n",
      "(bronc ⟂ lung | smoke)\n",
      "(smoke ⟂ xray | lung, bronc)\n",
      "(xray ⟂ smoke | lung, bronc)\n",
      "(lung ⟂ bronc | smoke)\n",
      "[bnlearn] >Nodes: ['smoke', 'lung', 'bronc', 'xray']\n",
      "[bnlearn] >Edges: [('smoke', 'lung'), ('smoke', 'bronc'), ('lung', 'xray'), ('bronc', 'xray')]\n"
     ]
    }
   ],
   "source": [
    "# Print the CPDs\n",
    "bn.print_CPD(DAG)\n",
    "# At this point we have a DAG with the learned CPDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are at this part, you combined your expert knowledge with a data set! Now we can make inferences which allows to ask questions to the model. Let me demonstrate a few questions.\n",
    "\n",
    "</br>\n",
    "\n",
    "- **Question 1:**\n",
    "What is the probability of lung-cancer, given that we know that patient does smoke?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----------+\n",
      "|    |   lung |         p |\n",
      "+====+========+===========+\n",
      "|  0 |      0 | 0.0330251 |\n",
      "+----+--------+-----------+\n",
      "|  1 |      1 | 0.966975  |\n",
      "+----+--------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "q1 = bn.inference.fit(DAG, variables=['lung'], evidence={'smoke':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "**Question 2:**\n",
    "What is the probability of bronchitis, given that we know that patient does smoke?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----------+\n",
      "|    |   bronc |        p |\n",
      "+====+=========+==========+\n",
      "|  0 |       0 | 0.311002 |\n",
      "+----+---------+----------+\n",
      "|  1 |       1 | 0.688998 |\n",
      "+----+---------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "q2 = bn.inference.fit(DAG, variables=['bronc'], evidence={'smoke':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "**Question 3:**\n",
    "Lets add more information to our inference. What is the probability of lung-cancer, given that we know that patient does smoke and also has bronchitis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----------+\n",
      "|    |   lung |         p |\n",
      "+====+========+===========+\n",
      "|  0 |      0 | 0.0330251 |\n",
      "+----+--------+-----------+\n",
      "|  1 |      1 | 0.966975  |\n",
      "+----+--------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "q3 = bn.inference.fit(DAG, variables=['lung'], evidence={'smoke':1, 'bronc':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "**Question 4:**\n",
    "Lets specify the question even more. What is the probability of lung-cancer or bronchitis, given that we know that patient does smoke but did not had xray?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Variable Elimination..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------+-----------+\n",
      "|    |   bronc |   lung |         p |\n",
      "+====+=========+========+===========+\n",
      "|  0 |       0 |      0 | 0.0915345 |\n",
      "+----+---------+--------+-----------+\n",
      "|  1 |       0 |      1 | 0.226912  |\n",
      "+----+---------+--------+-----------+\n",
      "|  2 |       1 |      0 | 0.194173  |\n",
      "+----+---------+--------+-----------+\n",
      "|  3 |       1 |      1 | 0.487381  |\n",
      "+----+---------+--------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "q4 = bn.inference.fit(DAG, variables=['bronc','lung'], evidence={'smoke':1, 'xray':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a causal model when you have data and no domain knowledge\n",
    "\n",
    "Suppose that we have the medical records of hundreds or even thousands patients treatment regarding shortness-of-breath (dyspnoea). Our goal is to determine the causality across variables given the data set.\n",
    "We use structure learning to estimate the DAG structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pypickle] Pickle file loaded: [c:\\Users\\miche\\Dropbox\\PhD\\Courses\\Causality\\causality-course\\lectures\\data\\smoke_dataset.pkl]\n",
      "[bnlearn] >Computing best DAG using [cs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working for n conditional variables: 5: 100%|██████████| 5/5 [00:00<00:00,  6.59it/s]\n",
      "Working for n conditional variables: 5: 100%|██████████| 5/5 [00:00<00:00,  6.95it/s]\n"
     ]
    }
   ],
   "source": [
    "df = bn.load(filepath='data/smoke_dataset.pkl')\n",
    "# Structure learning on the data set\n",
    "model_estimated = bn.structure_learning.fit(df, methodtype='cs', scoretype='bic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the learned DAG and examine the structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Pages: 1 -->\n<svg width=\"210pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 209.74 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 205.74,-256 205.74,4 -4,4\"/>\n<!-- either -->\n<g id=\"node1\" class=\"node\">\n<title>either</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"113.5\" cy=\"-90\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"113.5\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">either</text>\n</g>\n<!-- xray -->\n<g id=\"node2\" class=\"node\">\n<title>xray</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"113.5\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"113.5\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">xray</text>\n</g>\n<!-- either&#45;&gt;xray -->\n<g id=\"edge1\" class=\"edge\">\n<title>either&#45;&gt;xray</title>\n<path fill=\"none\" stroke=\"black\" d=\"M113.5,-71.7C113.5,-63.98 113.5,-54.71 113.5,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"117,-46.1 113.5,-36.1 110,-46.1 117,-46.1\"/>\n</g>\n<!-- dysp -->\n<g id=\"node3\" class=\"node\">\n<title>dysp</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"36.5\" cy=\"-18\" rx=\"28.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"36.5\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dysp</text>\n</g>\n<!-- either&#45;&gt;dysp -->\n<g id=\"edge2\" class=\"edge\">\n<title>either&#45;&gt;dysp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.54,-74.5C86.63,-64.58 71.99,-51.26 59.78,-40.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"61.92,-37.38 52.17,-33.25 57.21,-42.56 61.92,-37.38\"/>\n</g>\n<!-- bronc -->\n<g id=\"node4\" class=\"node\">\n<title>bronc</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"32.5\" cy=\"-90\" rx=\"32.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"32.5\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">bronc</text>\n</g>\n<!-- bronc&#45;&gt;dysp -->\n<g id=\"edge3\" class=\"edge\">\n<title>bronc&#45;&gt;dysp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M33.49,-71.7C33.93,-63.98 34.46,-54.71 34.95,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"38.44,-46.29 35.52,-36.1 31.45,-45.89 38.44,-46.29\"/>\n</g>\n<!-- lung -->\n<g id=\"node5\" class=\"node\">\n<title>lung</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"87.5\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"87.5\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lung</text>\n</g>\n<!-- lung&#45;&gt;either -->\n<g id=\"edge4\" class=\"edge\">\n<title>lung&#45;&gt;either</title>\n<path fill=\"none\" stroke=\"black\" d=\"M93.66,-144.41C96.66,-136.34 100.34,-126.43 103.71,-117.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-118.55 107.2,-107.96 100.44,-116.11 107,-118.55\"/>\n</g>\n<!-- tub -->\n<g id=\"node6\" class=\"node\">\n<title>tub</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"159.5\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"159.5\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tub</text>\n</g>\n<!-- tub&#45;&gt;either -->\n<g id=\"edge5\" class=\"edge\">\n<title>tub&#45;&gt;either</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149.06,-145.12C143.38,-136.47 136.22,-125.58 129.82,-115.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"132.63,-113.74 124.21,-107.31 126.78,-117.59 132.63,-113.74\"/>\n</g>\n<!-- smoke -->\n<g id=\"node7\" class=\"node\">\n<title>smoke</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"48.5\" cy=\"-234\" rx=\"34.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"48.5\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">smoke</text>\n</g>\n<!-- smoke&#45;&gt;bronc -->\n<g id=\"edge7\" class=\"edge\">\n<title>smoke&#45;&gt;bronc</title>\n<path fill=\"none\" stroke=\"black\" d=\"M46.57,-215.87C43.84,-191.67 38.83,-147.21 35.58,-118.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"39.03,-117.73 34.43,-108.19 32.08,-118.52 39.03,-117.73\"/>\n</g>\n<!-- smoke&#45;&gt;lung -->\n<g id=\"edge6\" class=\"edge\">\n<title>smoke&#45;&gt;lung</title>\n<path fill=\"none\" stroke=\"black\" d=\"M57.74,-216.41C62.4,-208.04 68.16,-197.71 73.36,-188.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"76.51,-189.91 78.32,-179.47 70.4,-186.5 76.51,-189.91\"/>\n</g>\n<!-- tub_area -->\n<g id=\"node8\" class=\"node\">\n<title>tub_area</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"159.5\" cy=\"-234\" rx=\"42.49\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"159.5\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tub_area</text>\n</g>\n<!-- tub_area&#45;&gt;tub -->\n<g id=\"edge8\" class=\"edge\">\n<title>tub_area&#45;&gt;tub</title>\n<path fill=\"none\" stroke=\"black\" d=\"M159.5,-215.7C159.5,-207.98 159.5,-198.71 159.5,-190.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163,-190.1 159.5,-180.1 156,-190.1 163,-190.1\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x29e86135190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_from_model(model):\n",
    "    # plot\n",
    "    g = gr.Digraph()\n",
    "    \n",
    "    for i in range(0, len(model_estimated['model_edges'])):\n",
    "        g.edge(*model_estimated['model_edges'][i])\n",
    "    return g\n",
    "\n",
    "# Plot the DAG\n",
    "plot_from_model(model_estimated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Review of Causal Discovery Methods Based on Graphical Models](https://www.frontiersin.org/articles/10.3389/fgene.2019.00524/full)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f82454df3ab4669350e470cecfad51160e6fdff8e76eafd19d8880dd92d922a3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
