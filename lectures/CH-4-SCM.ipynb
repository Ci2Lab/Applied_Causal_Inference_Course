{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "333030af5f4a4fa6a16bb18625a6edfc",
    "deepnote_cell_height": 3363.34375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Chapter 4. Structural Causal Models\n",
    "\n",
    "**Structural equation modeling (SEM)** is a family of various methods scientists use in experimental and observational research. SEMs, also called **Structural Causal Models (SCM)**, are used to represent and analyze causal relationships among variables. The SCM model specifies the relationships between the variables through a system of linear equations, where the observed variables are considered as effects of the latent variables and potentially other observed variables. The structural model also includes error terms to account for measurement error and unobserved factors.\n",
    "\n",
    "\n",
    "In an SCM, variables are the equivalent of nodes in a DAG, and causal relationships are described using structural equations. Each variable is associated with a structural equation that expresses how it depends on its direct causes or parent variables in the causal graph. \n",
    "\n",
    "SCMs allow researchers to simulate the system's behavior under different interventions or manipulations by modifying the structural equations or setting specific values for variables. They provide a formal framework for reasoning about counterfactuals and estimating causal effects in the presence of confounding variables.\n",
    "\n",
    "\n",
    "\n",
    "## Graphs vs. Structural Equations\n",
    "\n",
    "We saw in Chapter 3 that: \n",
    "- **G+** Graph is an excellent tool for communicating with subject matter experts. \n",
    "- **G+** Graph can be a helpful way to translate assumptions into a formal model. \n",
    "- **G+** Graphs are also useful to see what restrictions (if any) our model puts on the joint distribution of the observed data.\n",
    "\n",
    "- **E+** As the model becomes more complicated, the equations get a lot more friendly to work with.\n",
    "- **E+** Equations may help you resist the urge to oversimplify.\n",
    "\n",
    "\n",
    "![img](img/ch4/Causal-Graphs-Advantages.png)\n",
    "\n",
    "\n",
    "## Structural Causal/Equation Model\n",
    "\n",
    "An **Structural Causal Model (SCM)** or **Structure Equation Model (SEM)** consists of:\n",
    "\n",
    "1. *Endogenous variables* $X = {X_1 , ..., X_J }$ \n",
    "    - Affected by other variables in the model\n",
    "    - May or may not be observed\n",
    "\n",
    "<br/>\n",
    "\n",
    "2. *Background (exogenous) variables* $U = {U_1 , ..., U_J }$ \n",
    "    - Not affected by other factors in the model\n",
    "    - Not observed\n",
    "    - $U_j$ is also called noise or error variables and $U$ is a joint distribution over noise variables.\n",
    "    - Each endogenous variable $X_j$ has an error $U_j$.\n",
    "\n",
    "<br/>\n",
    "\n",
    "3. *Functions* $F = \\lbrace f_{X_1} , ... , f_{X_J} \\rbrace $\n",
    "    - The functions $F$ define a set of $J$ **structural equations** for each of the endogenous variables:\n",
    "    \n",
    "    $X_j = f_{X_j}(Pa(X_j),U_{X_j}), j = 1,...,J$\n",
    "    \n",
    "    $Pa(X_j) \\subseteq X \\backslash Xj$\n",
    "    \n",
    "where $Pa(X_j)$ called **parents** of $X_j$.\n",
    "\n",
    "* The strutue of $F$ is based on prior knowledge of the subject matter, theory, prior research, or causal DAG.\n",
    "* We sometimes call the elements of $PA_j$ not only parents but also **direct causes** of $X_j$, \n",
    "* We call $X_j$ a **direct effect** of each of its **direct causes** $PA_j$. \n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "See a short video on [SCM](https://www.youtube.com/watch?v=dQeRqb0N6gs&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=33) made by Brady Neal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Graph for a SCM with W-A-Y Example: \n",
    "\n",
    "The graph $\\mathcal{G}$ of an SCM $\\mathfrak{C}$ is obtained by creating one node for each $X_j$ and drawing directed edges from each parent in $PA_j$ to $X_j$. \n",
    "\n",
    "![img](img/ch4/Graph-SEM.png)\n",
    "\n",
    "- Connect parents to children with a directed link.\n",
    "\n",
    "\n",
    "- Each endogenous variable $X_j$ has an error $U_j$ term or relys on a exogenous variable.\n",
    "\n",
    "\n",
    "- Potential dependence between errors or exogenous variables $U_j$ encoded in dashed lines/double headed errors.\n",
    "\n",
    "\n",
    "- We assume this graph $\\mathcal{G}$ is acyclic, without directed cycles/feedback loops.\n",
    "    - Instead feedback loops, we can use temporal ordering.\n",
    "    - In other words, we can extend graph (and corresponding structural equations) over time.\n",
    "    \n",
    "\n",
    "- We will work with recursive SCM. There is ordering between $X={X_1,...,X_J}$ such that each $X_j$ is a function of a subset $Pa(Xj)$ of its **predecessors**.\n",
    "    - Causes always precede their effects\n",
    "    - A natural source of ordering is *time*\n",
    "\n",
    "    $X_j = f_{X_j}(Pa(X_j),U_{X_j}), j = 1,...,J $ \n",
    "\n",
    "    $Pa(X_j) \\subseteq {X_1, ..., X_{j-1}}$\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "### Causal Exclusion in the W-A-Y Example:\n",
    "\n",
    "Exclusion restrictions on the graph encoded through absence of arrows between variables.\n",
    "- Absence of arrow means no direct effect\n",
    "\n",
    "![img](img/ch4/Graph-SEM-Excluded.png)\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "### Independence Assumptions in the W-A-Y Example:\n",
    "- Absence of double headed arrows between background (exogenous) variables or errors $U$ means those two errors are **independent**.\n",
    "    - It is an assumption on distribution $P_U$.\n",
    "    - We assume there is no unmesaured common cause between those two $U_j$\n",
    "\n",
    "![img](img/ch4/Graph-SEM-Independence.png)\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Proposition 4.1. (SCM Entailed Distributions):** An SCM $\\mathfrak{C}$ defines a unique distribution over the variables $X = ({X_1},...,{X_J})$ such that: \n",
    "    $$X_j = f_{X_j}(Pa(X_j),U_{X_j})$$  for  $j = 1,...,J$\n",
    "    \n",
    "We refer to it as the entailed distribution $P^\\mathfrak{C}_X$ and sometimes write $P_X$.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7d4b15c6e44f4895808d2875a27c5e72",
    "deepnote_cell_height": 2134.328125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<br/>\n",
    "\n",
    "## Interventions on a SCM\n",
    "\n",
    "When performing interventions in an SCM, we set the value of a particular variable to a specific value or distribution, typically referred to as the intervention or treatment. By doing so, the researcher can observe how the changes propagate through the structural model and affect the values of other variables, providing insights into the causal relationships between variables.\n",
    "\n",
    "- When we intervene on variable $X_j$ and set it to a specific outcome. We expect that this intervention changes the distribution of the system compared to its earlier behavior without intervention. \n",
    "\n",
    "    - Even if variable $X_j$ was causally influenced by other variables before, it is now influenced by nothing else. \n",
    "    - $X_j$ has no more causal parents. \n",
    "\n",
    "- The autonomy of structural equations means that we can make a targeted modification to the set of equations in order to represent our intervention of interest.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Proposition 4.2. (Intervention Distribution):** [source](https://mitpress.mit.edu/books/elements-causal-inference) \n",
    "\n",
    "Consider an SCM $\\mathfrak{C}$ and its entailed distribution $P^\\mathfrak{C}_X$. We replace one (or several) of the structural assignments to obtain a new SCM $\\tilde{\\mathfrak{C}}$. \n",
    "\n",
    "<br/>\n",
    "\n",
    "Assume that we replace the assignment for $X_j$ by:\n",
    "\n",
    "$X_j = \\tilde{f}_{X_j}(\\tilde{Pa}(X_j),U_{X_j})$.\n",
    "\n",
    "<br/>\n",
    "\n",
    "We then call the entailed distribution of the new SCM $\\tilde{\\mathfrak{C}}$ an **intervention distribution** and say that the variables which structural assignment we have replaced have been **intervened** on. We denote the new distribution $P^{\\tilde{\\mathfrak{C}}}_X$ by:\n",
    "\n",
    "$P^{\\tilde{\\mathfrak{C}}}_X = P^{\\mathfrak{C} ; do(\\tilde{f}_{X_j}(\\tilde{Pa}(X_j),U_{X_j}))}_X$.\n",
    "\n",
    "<br/>\n",
    "\n",
    "The set of noise (error) variables in $\\tilde{\\mathfrak{C}}$ now contains both some “new” $\\tilde{U}$ 's and some \"old\" $U$'s, all of which are required to be jointly independent.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "### Intervention on A in the A-Y Example:\n",
    "\n",
    "- We intervene on the system to set $A=1$ and we replace $f_A$ with constant function $A=1$.\n",
    "\n",
    "![img](img/ch4/Grpah-SEM-Intervene.png)\n",
    "\n",
    "- $Y_a(u)$ is defined as the solution to the equation $f_Y$ under an intervention on the system of equations to set $A=a$ (with input $U_Y=u$).\n",
    "- We can think of $u$ as a particular realization of (values for) the background factors\n",
    "- $P_{U_Y}$ and $F$ induce a probability distribution on $Y_a$ just as they do on $Y$.\n",
    "- $Y_a$ is a **post-intervention** or a **counterfactual** random variable.\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "### Intervention on Targets in a Simple Prediction Example:\n",
    "\n",
    "This example considers prediction. It shows that even though some variables may be good predictors for a target variable $Y$ , intervening on them may leave the target variable unaffected. \n",
    "\n",
    "![img](img/ch4/Exp_Predictors_Intervention_Targets.png)\n",
    "\n",
    "Consider the following SCM $\\mathfrak{C}$:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    " X_1 = U_{X_1}\\\\\n",
    " Y = X_1 + U_Y\\\\\n",
    " X_2 = Y + U_{X_2}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "with following distribution being jointly independent:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "U_{X_1} \\stackrel{iid}{\\sim} \\mathcal{N}(0,1) \\\\\n",
    "U_{X_2} \\stackrel{iid}{\\sim} \\mathcal{N}(0,0.1) \\\\\n",
    "U_{Y} \\stackrel{iid}{\\sim} \\mathcal{N}(0,1) \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Case 1, Intervene on $X_2$:** \n",
    "\n",
    "We are interested in predicting $Y$ from $X_1$ and $X_2$. Clearly, $X_2$ is a better predictor for $Y$ than $X_1$ is. For example, a linear model without $X_2$ leads to a (significantly) larger mean squared error than a linear model without $X_1$ would.\n",
    "\n",
    "\n",
    "However, if we want to study $Y$, intervention on $X_2$ is useless. In other words, no matter how strongly we intervene on $X_2$, the distribution of $Y$ remains unaffected\n",
    "\n",
    "$P^{\\mathfrak{C} ; do(X_2 = \\stackrel{\\sim}{U})}_Y = P^{\\mathfrak{C}}_Y$\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Case 2, Intervene on $X_1$:** \n",
    "\n",
    "An intervention on $X_1$, however, does change the distribution $Y$.\n",
    "\n",
    "$P^{\\mathfrak{C} ; do(X_1 = \\stackrel{\\sim}{U})}_Y = \\mathcal{N}(E(U_Y) + E(\\stackrel{\\sim}{U}), var (U_Y) + var(\\stackrel{\\sim}{U}))$ \n",
    "\n",
    "\n",
    "$P^{\\mathfrak{C} ; do(X_1 = \\stackrel{\\sim}{U})}_Y \\neq P^{\\mathfrak{C}}_Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## Calculating Intervention Distributions\n",
    "\n",
    "This section is based on Chapter 6 of the Element of Causal Inference Book, [link](https://mitpress.mit.edu/9780262037310/elements-of-causal-inference/). \n",
    "\n",
    "We use a trivial but powerful **invariance** statement for calculating intervention distributions in SCM $\\mathfrak{C}$ with $p a(j):=\\mathbf{P A}_{j}^{\\mathcal{G}}$:\n",
    "\n",
    "$$\n",
    "p^{\\tilde{\\mathfrak{C}}}\\left(x_{j} \\mid x_{p a(j)}\\right)=p^{\\mathfrak{C}}\\left(x_{j} \\mid x_{p a(j)}\\right)\n",
    "$$ \n",
    "<p style='text-align: center;'> (Eq.1) </p>\n",
    "\n",
    "where the SCM $\\tilde{\\mathfrak{C}}$ is constructed from $\\mathfrak{C}$ by **intervening** on (some) $X_k$ but not on $X_j$.\n",
    "\n",
    "- Equation above shows that causal relationships are **autonomous** under interventions. This property is therefore sometimes called **autonomy**. It means if we intervene on a variable, then the other mechanisms remain invariant.\n",
    "- if we dont change $X_j$ and its parents and change a $X_k$, the  $p(x_{j} \\mid x_{p a(j)})$ remains unchanged.\n",
    "\n",
    "\n",
    "The autonomy formula is the base for the **G-formula** (Robins, 1986), **truncated factorization** (Pearl, 1993), or **manipulation theorem** (Spirtes, 2000) that we have seen in Chapter 3. To refresh our minds, we repeat those formulas.  \n",
    "\n",
    "We start with an SCM $\\mathfrak{C}$ with structural assignments with density $p^{\\mathfrak{C}}$:\n",
    "\n",
    "$$\n",
    "X_{j}:=f_{j}\\left(X_{pa(j)}, U_{j}\\right), \\quad j=1, \\ldots, d\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.2) </p>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Using Markov property, we have:\n",
    "\n",
    "$$\n",
    "p^{\\mathfrak{C}}\\left(x_{1}, \\ldots, x_{d}\\right)=\\prod_{j=1}^{d} p^{\\mathfrak{C}}\\left(x_{j} \\mid x_{p a(j)}\\right)\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.3) </p>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "We do an **intervention**, so the SCM $\\mathfrak{\\tilde{C}}$ evolves from $\\mathfrak{C}$ after the operation $do\\left(X_{k}:=\\tilde{U}_{k}\\right)$, where using random distribution $\\tilde{U}_{k}$ changes the density to $\\tilde{p}$. Again, we use the Markov assumption:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p^{\\mathfrak{C} ; d o\\left(X_{k}:=\\tilde{U}_{k}\\right)}\\left(x_{1}, \\ldots, x_{d}\\right) &=\\prod_{j \\neq k} p^{\\mathfrak{C} ; d o\\left(X_{k}:=\\tilde{U}_{k}\\right)}\\left(x_{j} \\mid x_{p a(j)}\\right) \\cdot p^{\\mathfrak{C} ; d o\\left(X_{k}:=\\tilde{U}_{k}\\right)}\\left(x_{k}\\right) \\\\\n",
    "&=\\prod_{j \\neq k} p^{\\mathfrak{C}}\\left(x_{j} \\mid x_{p a(j)}\\right) \\tilde{p}\\left(x_{k}\\right) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.4) </p>\n",
    "\n",
    "\n",
    "- **The *(Eq.4)* allows us to compute an interventional statement (left-hand side) from observational quantities (right-hand side).**<font/>\n",
    "\n",
    "- **In other words, Eq.4 allows us to compute statements about intervention distributions even though we have never seen data directly from the intervention.**\n",
    "\n",
    "\n",
    "We can rewrite interventional statement in *(Eq.4)* as following to see an special case:\n",
    "\n",
    "$$\n",
    "p^{\\mathfrak{C} ; d o\\left(X_{k}:=a\\right)}\\left(x_{1}, \\ldots, x_{d}\\right)=\\left\\{\\begin{array}{cl}\n",
    "\\prod_{j \\neq k} p^{\\mathfrak{C}}\\left(x_{j} \\mid x_{p a(j)}\\right) & \\text { if } x_{k}=a \\\\\n",
    "0 & \\text { otherwise }\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.5) </p>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "We have seen in Chapter 2 that conditioning and intervening (using $do(*)$) are usually two different operations. However, these operations become identical for variables with no parents (source variables or exogenous variables). \n",
    "\n",
    "Let us assume that $X_1$ is such a source node without loss of generality. Then, we have:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p^{\\mathfrak{C}}\\left(x_{2}, \\ldots, x_{d} \\mid x_{1}=a\\right) &=\\frac{p\\left(x_{1}=a\\right) \\prod_{j=2}^{d} p^{\\mathfrak{C}}\\left(x_{j} \\mid x_{p a(j)}\\right)}{p\\left(x_{1}=a\\right)} \\\\\n",
    "&=p^{\\mathfrak{C} ; d o\\left(X_{1}:=a\\right)}\\left(x_{2}, \\ldots, x_{d}\\right) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.6) </p>\n",
    "\n",
    "\n",
    "**Eq. 4 and Eq.5** may be confusing. To better understand thier application, let's see the following example...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for Calculating Intervention in a SCM: Kidney Stone Treatments\n",
    "\n",
    "This example is from a famous data set for the success rates of two treatments for kidney stones. It is a classic example of Simpson’s paradox and also used in [Bottou et al., 2013](https://jmlr.org/papers/v14/bottou13a.html), [Charig et al., 1986](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1339981/). \n",
    "\n",
    "<img src=\"img/ch4/Kidney-stones-xray.png\" width=\"300\">\n",
    "\n",
    "\n",
    "\n",
    "Out of **700 patients**: \n",
    "\n",
    "* **350** were treated with open surgery (treatment $T = A$, with 78% recovery rate)\n",
    "* the other **350** were treated with percutaneous nephrolithotomy ($T = B$, with 83% recovery rate), a surgical procedure to remove kidney stones by a small puncture wound. \n",
    "\n",
    "\n",
    "If we do not know anything other than the overall recovery rates and neglect side effects, many people would prefer treatment $B$ if they had to decide. Right? (Assume we dont know about the Simpson's paradox)\n",
    "\n",
    "\n",
    "The table below shows the data.\n",
    "\n",
    "<img src=\"img/ch4/Kidney-stones.png\" width=\"500\">\n",
    "\n",
    "\n",
    "### Solution Part 1: Avoiding Simpson Paradox with Intervention\n",
    "\n",
    "Observing the data in more detail, we can categorize kidney stones into small and large stones. Although the overall success rate of treatment $B$ seems better, we realize that open surgery (Treatment $A$) performs better in both patients with small kidney stones and patients with large kidney stones. \n",
    "\n",
    "**How do we deal with this inversion of conclusion?**\n",
    "\n",
    "\n",
    "**First Viewpoint:** \n",
    "\n",
    "- Larger stones are more severe than small stones, and treatment had to deal with many more difficult cases (even though the total number of patients assigned to $A$ and $B$ are equal). This is why treatment $A$ can look worse than $B$ on the entire population but better in both subgroups. \n",
    " - 263 out of 350 patients in treatment $A$ have large stones.\n",
    " - just 80 patients out of 350 in treatment $B$ have large stones.\n",
    "\n",
    "<br/>\n",
    "\n",
    "- The imbalance in assignment could, for example, arise if the medical doctors expect treatment $A$ to be better than treatment $B$ and therefore assign the difficult cases with large stones to treatment $A$ with a higher probability. \n",
    "\n",
    "**Second Viewpoint:** \n",
    "\n",
    "- We propose to use the language of interventions to formulate the precise question we are interested in. \n",
    "\n",
    "- Our goal is not whether treatment $T = A$ or treatment $T = B$ was more successful in this particular study but how the treatments outcomes compare when:\n",
    " - $P^{\\mathfrak{C} ; d o(T:=A)}$, or we force all patients to take treatment $A$. \n",
    " - $P^{\\mathfrak{C} ; d o(T:=B)}$, or we force all patients to take treatment $B$. \n",
    " - $P^{\\mathfrak{C} ; d o\\left(T:=\\tilde{N}_{T}\\right)}$, or each patient is assigned randomly to one of the treatments.\n",
    "\n",
    "<br/>\n",
    "\n",
    "- These three situations concern an **intervention distribution $P^{\\mathfrak{C} ; d o()}$** that is different from the **observational distribution $P$**. \n",
    "\n",
    "\n",
    "### Solution Part 2: Compute Intervention Distributions $P^{\\mathfrak{C} ; d o(T:=A)}, P^{\\mathfrak{C} ; d o(T:=B)}, \\text { or } P^{\\mathfrak{C} ; d o\\left(T:=\\tilde{N}_{T}\\right)}$\n",
    "\n",
    "We assume the true underlying SCM $\\mathfrak{C}$ allows for the following graph where $Z$ is the size of the stone, $T$ the treatment, and $R$ the recovery (all binary).\n",
    "\n",
    "<img src=\"img/ch4/Kidney-stones-graph.png\" width=\"500\">\n",
    "\n",
    "\n",
    "Some points from the graph:\n",
    "\n",
    "- The recovery is influenced by the treatment and the size of the stone. \n",
    "- The treatment itself depends on the size. \n",
    "- A large proportion of difficult cases was assigned to treatment $A$,the open surgery. \n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "We consider two diffrent variation of SCM $\\mathfrak{C}$ based on the type of the treatment:\n",
    "\n",
    "- We force all patients to take treatment $A$: SCM $\\mathfrak{C}_A$ obtained after replacing the structural assignment for $T$ with $T := A$ with corresponding probability distributions $P^{\\mathfrak{C}_A}$\n",
    "\n",
    "- We force all patients to take treatment $B$: SCM $\\mathfrak{C}_B$ obtained after replacing the structural assignment for $T$ with $T := B$ with corresponding probability distributions $P^{\\mathfrak{C}_B}$\n",
    "\n",
    "Given that a patient is diagnosed with a kidney stone without knowing its size, we should base our choice of treatment on a comparison between:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "&\\mathbb{E}^{\\mathfrak{C}_{A}} R=P^{\\mathfrak{C}_{A}}(R=1)=P^{\\mathfrak{C} ; d o(T:=A)}(R=1) \\\\\n",
    "&\\mathbb{E}^{\\mathfrak{C}_{B}} R=P^{\\mathfrak{C}_{B}}(R=1)=P^{\\mathfrak{C} ; d o(T:=B)}(R=1)\n",
    "\\end{cases}\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.7) </p>\n",
    "\n",
    "Given that we have observed data from $\\mathfrak{C}$, **how can we estimate these quantities?**\n",
    "\n",
    "Below is the calculation of $P^{\\mathfrak{C}_{A}}(R=1)$.\n",
    "Remember it is given that a patient is diagnosed with a kidney stone without knowing its size,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P^{\\mathfrak{C}_{A}}(R=1) &=\\sum_{z=0}^{1} P^{\\mathfrak{C}_{A}}(R=1, T=A, Z=z) \\\\\n",
    "&=\\sum_{z=0}^{1} P^{\\mathfrak{C}_{A}}(R=1 \\mid T=A, Z=z) P^{\\mathfrak{C}_{A}}(T=A, Z=z) \\\\\n",
    "&=\\sum_{z=0}^{1} P^{\\mathfrak{C}_{A}}(R=1 \\mid T=A, Z=z) P^{\\mathfrak{C}_{A}}(Z=z) \\\\\n",
    "& \\stackrel{(Eq.1)}{=} \\sum_{z=0}^{1} P^{\\mathfrak{C}}(R=1 \\mid T=A, Z=z) P^{\\mathfrak{C}}(Z=z) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.8) </p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "The last step of *Eq.8* achieved from the invariance equation (Eq.1). Using observational data in the table above, we can estimate $P^{\\mathfrak{C}_{A}}(R=1)$. \n",
    "\n",
    "In words, it means the probability of recovery if we force all patients to use treatment $A$ including those ones who has small and big stones is:\n",
    "\n",
    "$$\n",
    "P^{\\mathfrak{C} ; d o(T:=A)}(R=1) = P^{\\mathfrak{C}_{A}}(R=1) \\approx 0.93 \\cdot \\frac{357}{700}+0.73 \\cdot \\frac{343}{700}=0.832\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.9) </p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Similarly, we can calculate:\n",
    "\n",
    "$$\n",
    "P^{\\mathfrak{C} ; d o(T:=B)}(R=1) = P^{\\mathfrak{C}_{B}}(R=1) \\approx 0.87 \\cdot \\frac{357}{700}+0.69 \\cdot \\frac{343}{700} \\approx 0.782\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.10) </p>\n",
    "\n",
    "\n",
    "**Therefore, we conclude that we would rather go for treatment $A$. What do we see in the table?!**\n",
    "\n",
    "<br/>\n",
    "\n",
    "We also see that the **average causal effect (ACE)** for this binary treatments is positive.\n",
    "\n",
    "$$\n",
    "P^{\\mathfrak{C}_{A}}(R=1)-P^{\\mathfrak{C}_{B}}(R=1) \\approx 0.832-0.782\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.11) </p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Notice that intervention is different from simple conditioning (the problem with Simpson paradox). \n",
    "\n",
    "In this case conditioning has even the opposite sign of the ACE.\n",
    "\n",
    "$$\n",
    "P^{\\mathfrak{C}}(R=1 \\mid T=A)-P^{\\mathfrak{C}}(R=1 \\mid T=B)=0.78-0.83\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.12) </p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "This kidney stine example highlights the difference between **intervening** and **conditioning**. \n",
    "\n",
    "In terms of densities, it reads:\n",
    "\n",
    "$$\n",
    "p^{\\mathfrak{C} ; d o(T:=t)}(r)=\\sum_{z} p^{\\mathfrak{C}}(r \\mid z, t) p^{\\mathfrak{C}}(z) \\neq \\sum_{z} p^{\\mathfrak{C}}(r \\mid z, t) p^{\\mathfrak{C}}(z \\mid t)=p^{\\mathfrak{C}}(r \\mid t) .\n",
    "$$\n",
    "<p style='text-align: center;'> (Eq.13) </p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "See a short video on [Interventions with SCMs](https://www.youtube.com/watch?v=f-7AgoMlrnE&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=34) made by Brady Neal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Do-Calculus\n",
    "\n",
    "So far, we have talked about causality in terms of interventions. In simple words, we say that $X$ causes $Y$ if an intervention in $X$ changes $Y$, while intervention in $Y$ does not necessarily result in a change in $X$. Remeber the \"Simple Prediction Example\" that we have seen.\n",
    "\n",
    "<br/>\n",
    "\n",
    "The **do-operator** is a mathematical representation of physical intervention. For example, in our $W → A → Y$ model, we can simulate an intervention in $A$ by deleting all the incoming arrows to $A$, and manually setting $A$ to some value $a_0$.\n",
    "\n",
    "\n",
    "<img src=\"img/ch4/do-operator.png\" width=\"400\">\n",
    "\n",
    "For example, suppose we want to ask, *will increasing the marketing budget boost Smoked Salmon sales?*\n",
    "\n",
    "If we have a causal model that includes marketing spending and sales, we can simulate what would happen if we were to increase the marketing budget and assess whether the change in Smoked Salmon sales is worth it. In other words, we can *evaluate the causal effect* of marketing on sales. \n",
    "\n",
    "<br/>\n",
    "\n",
    "<font color='blue'>**The importance of do-operator is that it allows us to simulate experiments, given we know the causal model. See Eq.4 again!**<font/>\n",
    "\n",
    "<br/>\n",
    "    \n",
    "See a short video on [Do-Operator](https://www.youtube.com/watch?v=U8t2PsN4hIc&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=28) made by [Brady Neal](https://www.bradyneal.com/causal-inference-course).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='red'> Pass<font/>\n",
    "\n",
    "## Three Rules of Do-Calculus\n",
    "\n",
    "\n",
    "Following is a complete set of three rules that outline how to use the **do-operator** suggested by [Judea Pearl, 2009](http://bayes.cs.ucla.edu/BOOK-2K/). \n",
    "\n",
    "Notice that **do-calculus** can translate **interventional distributions** (i.e., probabilities with the do-operator) into **observational distributions** (i.e., probabilities without the do-operator). This can be seen by rules 2 and 3. \n",
    "\n",
    "Given a graph $\\mathcal{G}$ and disjoint subsets $\\mathbf{X, Y, Z, W}$, we have:\n",
    "\n",
    "\n",
    "### Rule 1. Insertion/deletion of observations:\n",
    "    \n",
    "$$\n",
    "p^{\\mathfrak{C} ; d o(\\mathbf{X}:=\\mathbf{x})}(\\mathbf{y} \\mid \\mathbf{z}, \\mathbf{w})=p^{\\mathfrak{C} ; d o(\\mathbf{X}:=\\mathbf{x})}(\\mathbf{y} \\mid \\mathbf{w})\n",
    "$$\n",
    "\n",
    "if $\\mathbf{Y}$ and $\\mathbf{Z}$ are d-separated by $\\mathbf{X,W}$ in a graph where incoming edges in $\\mathbf{X}$ have been removed. \n",
    "\n",
    "In simple words, $\\mathbf{Z}$ is irrelevant to $\\mathbf{Y}$.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Rule 2. Action/observation exchange:\n",
    "\n",
    "$$\n",
    "p^{\\mathfrak{C} ; d o(\\mathbf{X}:=\\mathbf{x}, \\mathbf{Z}=\\mathbf{z})}(\\mathbf{y} \\mid \\mathbf{w})=p^{\\mathfrak{C} ; d o(\\mathbf{X}:=\\mathbf{x})}(\\mathbf{y} \\mid \\mathbf{z}, \\mathbf{w})\n",
    "$$\n",
    "\n",
    "if $\\mathbf{Y}$ and $\\mathbf{Z}$ are d-separated by $\\mathbf{X,W}$ in a graph where incoming edges in $\\mathbf{X}$ and outgoing edges from $\\mathbf{Z}$ have been removed. \n",
    "\n",
    "In simple words, $\\mathbf{X \\cup W}$ blocks all back-door paths from $\\mathbf{Z}$ to $\\mathbf{Y}$.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Rule 3. Insertion/deletion of actions:\n",
    "\n",
    "$$\n",
    "p^{\\mathfrak{C} ; d o(\\mathbf{X}:=\\mathbf{x}, \\mathbf{Z}=\\mathbf{z})}(\\mathbf{y} \\mid \\mathbf{w})=p^{\\mathfrak{C} ; d o(\\mathbf{X}:=\\mathbf{x})}(\\mathbf{y} \\mid \\mathbf{w})\n",
    "$$\n",
    "\n",
    "if $\\mathbf{Y}$ and $\\mathbf{Z}$ are d-separated by $\\mathbf{X,W}$ in a graph where incoming edges in $\\mathbf{X}$ and $\\mathbf{Z(W)}$ have been removed. Here $\\mathbf{Z(W)}$ is the subset of nodes in $\\mathbf{Z}$ that are not ancestors of any node in $\\mathbf{W}$ in a graph that is obtained from $\\mathcal{G}$ after removing all edges into $\\mathbf{X}$.\n",
    "\n",
    "In simple words, there is no causal path from $\\mathbf{Z}$ to $\\mathbf{Y}$.\n",
    "    \n",
    "<br/>\n",
    "    \n",
    "See a short video on [Do-Calculus Rules](https://www.youtube.com/watch?v=M-mF6bXlxHI&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=40) from Brady Neal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3ab26dcd97a4d69a239c13402c708c1",
    "deepnote_cell_height": 2154.171875,
    "deepnote_cell_type": "markdown",
    "owner_user_id": "a91a2c6a-0c99-4421-a773-926bd3919ed9",
    "tags": []
   },
   "source": [
    "## Causal Models and Counterfactuals\n",
    "\n",
    "Humans often think in the form of **counterfactuals**: *“I should have taken the train.”* or *“We should have invested in Bitcoin in January 2019!”* are only a few examples. \n",
    "\n",
    "\n",
    "Counterfactuals have a long history as humankind. For example, Titus Livius discusses in 25 BC what would have happened if Alexander the Great had not died on his way back from Persia and had attacked Rome. Livy argues that Rome and Carthage would have joined forces to crush the Macedonian army. [Geradin and Girgenson, 2011](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1970917). \n",
    "\n",
    "\n",
    "<img src=\"img/ch4/Alexander_mosaic.jpeg\" width=\"400\">\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "In structural equation models, variables are represented as functions of other variables, capturing the causal relationships among them. By manipulating the values of variables in the model and observing the resulting changes in the outcome variable, researchers can estimate the **counterfactual outcome** or what would have happened under different conditions. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Definition 4.3. (Counterfactuals):** Counterfactual corresponds to updating the exogenous vaiables of an SCM $\\mathfrak{C}$ (by conditioning) and then performing an intervention.\n",
    "\n",
    "Consider an SCM $\\mathfrak{C} = (S,P_U)$ over variables $X$. Given some observations $x$, we define a *counterfactual SCM* by replacing some exogenous variables (random distributions or noise):\n",
    "\n",
    "$$\n",
    "\\mathfrak{C}_{\\mathbf{X}=\\mathbf{x}}:=\\left(\\mathbf{S}, P_{\\mathbf{U}}^{\\mathfrak{C} \\mid \\mathbf{X}=\\mathbf{x}}\\right)\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "P_{\\mathbf{U}}^{\\mathfrak{C} \\mid \\mathbf{X}=\\mathbf{x}} = P_{\\mathbf{U} \\mid \\mathbf{X}=\\mathbf{x}}^{}\n",
    "$$\n",
    "\n",
    "The new set of exogenous variables need not be jointly independent anymore. \n",
    "\n",
    "*Counterfactual* statements can now be seen as *do-statements* in the new counterfactual SCM.\n",
    "\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "See a short video on [Counterfactuals](https://www.youtube.com/watch?v=f8PEpthLlN4&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=81) made by Brady Neal.\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Example for Computing Counterfactuals: a 3 Integers Model\n",
    "\n",
    "This example is from [Elements of Causal Inference Book, Chapter 6](https://mitpress.mit.edu/books/elements-causal-inference). \n",
    "Consider the following SCM $\\mathfrak{C}$:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "X = U_X \\\\\n",
    "Y = X^{2} + U_Y\\\\\n",
    "Z = 2Y + X + U_Z\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "with uniformly distributed noise values on the integers between −5 and 5:\n",
    "\n",
    "$$\n",
    "U_{X}, U_{Y}, U_{Z} \\stackrel{\\text { iid }}{\\sim} \\mathrm{U}(\\{-5,-4, \\ldots, 4, 5\\})\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Case 1: Observation:** \n",
    "\n",
    "We assume that we observe $(X,Y,Z) = (1,2,4)$. We have a observational statement: “ If we observe $X = 1$, $Y = 2$, and $Z = 4$, then Noise values will be $(U_X , U_Y , U_Z) = (1, 1, -1)$\"\n",
    "\n",
    "Then $P_{\\mathbf{U}}^{\\mathfrak{C} \\mid \\mathbf{X}=\\mathbf{x}}$ puts a point mass on $(U_X , U_Y , U_Z) = (1, 1, -1)$ because here all noise terms can be uniquely reconstructed from the observations.\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Case 2: Counterfactual:** \n",
    "\n",
    "Agian, we assume that we observe $(X,Y,Z) = (1,2,4)$. Now, we also have a counterfactual statement: “$Z$ would have been 11 if we had $X$ been set to 2.\" We only changed $U_X$, $U_Y , U_Z$ reamin unchanged.\n",
    "\n",
    "Mathematically, this means that $P_{\\mathbf{Z}}^{\\mathfrak{C} \\mid \\mathbf{X}=\\mathbf{x};do(X=2)} = 11$ or it has $Z$ a point mass on 11. $Y$ would have been 5 if we had $X$ been set to 2.\n",
    "\n",
    "\n",
    "Counterfactuals notation may looks quite complicated. The following image provides further clarification:\n",
    "\n",
    "![img](img/ch4/Counterfactuals_notation.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "See a short video on [Computing Counterfactuals](https://www.youtube.com/watch?v=wuYda40rqgo&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=82) made by Brady Neal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "## Total Causal Effect\n",
    "\n",
    "We define the existence of a total causal effect as follows based on [Judea Pearl, 2009](https://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf) and Chapter 6 of [Elements of Causal Inference](https://mitpress.mit.edu/books/elements-causal-inference).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Definition 4.4. (Total Causal Effect):** Given an SCM $\\mathfrak{C}$ over nodes $X$, there is a total causal effect from $X$ to $Y$ for some exogenous variables $\\tilde{U}_{X}$ (random distribution or noise) if and only if:\n",
    "\n",
    "$$X \\not\\!\\perp\\!\\!\\!\\perp Y \\quad  in  P_{\\mathbf{X}}^{\\mathfrak{C} ; do\\left(X:=\\tilde{U}_{X}\\right)}$$\n",
    "\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "The existence of a total causal effect is also related to the existence of a directed path in the corresponding graph $\\mathcal{G}$. The correspondence, however, is not one-to-one. While a directed path is necessary for a total causal effect, it is not sufficient.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Proposition 4.5 (Graphical criteria for Total Causal Effects):** Assume we are given an SCM $\\mathfrak{C}$ with a corresponding graph $\\mathcal{G}$.\n",
    "\n",
    "- (i) If there is no directed path from $X$ to $Y$ , then there is no total causal effect.\n",
    "- (ii) Sometimes there is a directed path but no total causal effect.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Build a Structural Causal Model Step-by-Step\n",
    "\n",
    "<br/>\n",
    "\n",
    "## Impact of Beer consumption on happiness in HVL-Kronbar \n",
    "\n",
    "The example is inspired by [Berkeley's Causality course](https://www.ucbbiostat.com/labs) but adapted to our own Kronbar in Bergen's campus.\n",
    "\n",
    "### Background\n",
    "\n",
    "Suppose we are interested in the causal effect of beer consumption on happiness among our students. Specifically, we want to know if the average happiness would be higher if all students consumed beer or if all students did not. From a causal inference perspective, we want to know if there is a connection between beer consumption at Kronbar and happiness.\n",
    "\n",
    "**What do you think? :)**\n",
    "\n",
    "<img src=\"img/ch5/kronbar.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "\n",
    "As seen in the lecture, we have to first identify the variables (endogenous, exogenous), then draw a DAG to formalize our hypotheses and assumptions. Then we need structural equations to build a SCM from the DAG. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 0: Identify Variables and Assumptions\n",
    "\n",
    "We first need to identify the variables $X$ that are interesting and meaningful for the study (endogenous variables) and background (exogenous) variables $U$ that are unmeasured factors not included in $X$ that determine the values that the $X$ variables take.\n",
    "\n",
    "- Let $W_1$ be a measure of the student’s pre-exposure characteristic (e.g., sociality).\n",
    "\n",
    "- Let $W_2$ be an additional baseline variable, indicating whether the student has money to buy alcohol.\n",
    "\n",
    "- We consider a binary exposure $A$, indicating consumption of beer $(A=1)$ or not $(A=0)$.\n",
    "\n",
    "- $Y$ denote the outcome happiness.\n",
    "\n",
    "\n",
    "Finally, we suppose only $W_2$ affects the exposure $A$, but it has no direct effect on the happiness $Y$.\n",
    "\n",
    "The counterfactuals of interest are:\n",
    "\n",
    "$$Y_a : a \\in \\mathcal{A} = \\{0,1\\}$$\n",
    "\n",
    "$Y_1$ is the counterfactual happiness if a student drank beer and \n",
    "\n",
    "$Y_0$ is the counterfactual happiness if a student did not drink beer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Create a DAG\n",
    "\n",
    "This study can be translated into a directed acyclic graph below based on our background knowldge. \n",
    "\n",
    "These variables are related based on the following DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"139pt\" height=\"340pt\"\n",
       " viewBox=\"0.00 0.00 138.82 340.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 336)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-336 134.82,-336 134.82,4 -4,4\"/>\n",
       "<!-- U -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>U</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"101\" cy=\"-314\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"101\" y=\"-310.3\" font-family=\"Times,serif\" font-size=\"14.00\">U</text>\n",
       "</g>\n",
       "<!-- W1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>W1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-242\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\">W1</text>\n",
       "</g>\n",
       "<!-- U&#45;&gt;W1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>U&#45;&gt;W1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.02,-298.83C75.49,-288.87 61.22,-275.37 49.34,-264.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.62,-261.47 41.95,-257.14 46.81,-266.56 51.62,-261.47\"/>\n",
       "</g>\n",
       "<!-- W2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>W2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"65\" cy=\"-170\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\">W2</text>\n",
       "</g>\n",
       "<!-- U&#45;&gt;W2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>U&#45;&gt;W2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96.73,-296.15C90.56,-271.81 79.09,-226.57 71.76,-197.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.12,-196.66 69.27,-187.82 68.33,-198.38 75.12,-196.66\"/>\n",
       "</g>\n",
       "<!-- A -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"red\" cx=\"86\" cy=\"-94\" rx=\"18\" ry=\"18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"red\" cx=\"86\" cy=\"-94\" rx=\"22\" ry=\"22\"/>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-90.3\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n",
       "</g>\n",
       "<!-- U&#45;&gt;A -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>U&#45;&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.43,-295.99C104.58,-266.51 107.74,-204.11 101,-152 99.84,-143.03 97.69,-133.46 95.38,-124.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.72,-123.73 92.63,-115.06 91.99,-125.64 98.72,-123.73\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- U&#45;&gt;Y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>U&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.89,-296.14C111.7,-285.88 116.06,-272.41 118,-260 124.48,-218.59 142.92,-166.41 117,-72 114.19,-61.78 108.89,-51.5 103.45,-42.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.27,-40.67 97.83,-34.25 100.43,-44.53 106.27,-40.67\"/>\n",
       "</g>\n",
       "<!-- W1&#45;&gt;W2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>W1&#45;&gt;W2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.81,-224.76C40.42,-216.28 46.16,-205.71 51.32,-196.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.54,-197.61 56.23,-187.15 48.39,-194.27 54.54,-197.61\"/>\n",
       "</g>\n",
       "<!-- W1&#45;&gt;Y -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>W1&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M25.91,-223.8C25.12,-205.77 24.8,-176.68 29,-152 35.26,-115.14 39.7,-106.11 55,-72 59.34,-62.33 64.99,-52.17 70.27,-43.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.31,-45.11 75.57,-34.76 67.35,-41.44 73.31,-45.11\"/>\n",
       "</g>\n",
       "<!-- W2&#45;&gt;A -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>W2&#45;&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.77,-152.21C72.04,-144.19 74.83,-134.35 77.46,-125.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.84,-125.99 80.21,-115.42 74.11,-124.08 80.84,-125.99\"/>\n",
       "</g>\n",
       "<!-- A&#45;&gt;Y -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>A&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86,-71.99C86,-64.06 86,-54.91 86,-46.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.5,-46.31 86,-36.31 82.5,-46.31 89.5,-46.31\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f805bef27d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz as gr\n",
    "\n",
    "g = gr.Digraph()\n",
    "g.edge(\"U\", \"W1\")\n",
    "g.edge(\"U\", \"W2\")\n",
    "g.edge(\"U\", \"A\")\n",
    "g.edge(\"U\", \"Y\")\n",
    "\n",
    "g.edge(\"W1\", \"W2\")\n",
    "g.edge(\"W2\", \"A\")\n",
    "g.edge(\"W1\", \"Y\")\n",
    "g.edge(\"A\", \"Y\")\n",
    "g.node(\"A\", color=\"red\", shape=\"doublecircle\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Create a SCM\n",
    "\n",
    "\n",
    "Having the background knowlege and resultant DAG, we can make a SEM. Such a SEM has following variables:\n",
    "\n",
    "- Endogenous Nodes: $X = (W_1, W_2, A, Y )$\n",
    "- Exogenous (Unmeasured) Nodes: $U = (U_{W1}, U_{W2}, U_A, U_Y ) \\sim \\mathbb{P}_U$\n",
    "- Structural Equations $\\mathfrak{C}$\n",
    "\n",
    "\n",
    "The related structural model $\\mathfrak{C}$ has the following general funtional form:\n",
    "\n",
    "$$\n",
    "\\mathfrak{C} :=\n",
    "\\begin{cases}\n",
    "     &W_1 = f_{W1}(U_{W1}) \\\\\n",
    "     &W_2 = f_{W2}(W_1, U_{W2}) \\\\ \n",
    "     &A = f_A(W_1, W_2, U_A) \\\\\n",
    "     &Y = f_Y (W_1, A, U_Y ) \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Some notes:**\n",
    "\n",
    "- we collected some background knowledge first. For example, we looked into similar studies and talked to some experts.\n",
    "- We specified a model which reflects our limited knowledge of the data-generating system. \n",
    "- We did not place any assumptions on the joint distribution of the exogenous nodes. \n",
    "- We made only one exclusion restriction on $W_2$ to $A$. \n",
    "- Finally, we did not make any assumptions about the functional form of the structural equations. (Not yet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Specify the Causal Question\n",
    "\n",
    "The next step is to translate the scientific question into a formal causal quantity. In this example, we want to know: \n",
    "\n",
    "**Is the happiness increases with drinking more beer?**\n",
    "\n",
    "We can never know both individual treatment effect (drinking beer or not drinking) at the same time, because we only observe one of the potential outcomes at each time. So, we calculate the **average treatment effect (ATE)** to answer our causal question.\n",
    "\n",
    "The average treatment effect (ATE), defined as:\n",
    "\n",
    "$$\n",
    "ATE =\n",
    "\\mathbb{E}_{U,X} (Y_1) - \\mathbb{E}_{U,X} (Y_0)\n",
    "= \\mathbb{E}_{U,X} [f_Y(W_1,A=1,U_Y)] - \\mathbb{E}_{U,X} [f_Y(W_1,A=0,U_Y)]\n",
    "$$\n",
    "\n",
    "$ATE$ is the difference in the expected counterfactual happiness if all students were to drink beer and the expected counterfactual happiness if all students were not to drink beer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-01761fe7-314c-4a88-bb4c-dea2055ab59d",
    "deepnote_cell_height": 870.21875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### STEP 4:  Assuming the form of structural equations then simulate data\n",
    "\n",
    "Because we don't have actual data for this study, we need to generate (simulate) data. So, we consider a particular data generating process $\\mathbb{P}_{U,X}$. However, many data generation processes are compatible with our structural equations model or structural causal model $\\mathfrak{C}$. \n",
    "\n",
    "First, let's specify the structural causal model $\\mathfrak{C}$ with more details. We assume we looked at simillar studies in other universities and found following distrbutions for our variables plus functions.\n",
    "\n",
    "\n",
    "Each of the exogenous factors $U$ is drawn independently from the following distributions:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    U_{W1} \\sim Uniform(min=0, max=1) \\\\\n",
    "    U_{W2} \\sim Bernoulli(p=0.5) \\\\\n",
    "    U_{A} \\sim Normal(\\mu=-3, \\sigma^2=1) \\\\\n",
    "    U_{Y} \\sim Normal(\\mu=0, \\sigma^2=0.3^2)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Let us also specify the structural equations $\\mathfrak{C}$:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "     &W_1 = f_{W1}(U_{W1}) = \\mathbb{I}[U_{W1} < 0.6] \\\\\n",
    "     &W_2 = f_{W2}(W_1, U_{W2}) = W_1 + 2U_{W2} \\\\ \n",
    "     &A = f_A(W_1, W_2, U_A) = \\mathbb{I} [(1+W_1+2W_2+U_A) > 0] \\\\\n",
    "     &Y = f_Y (W_1, A, U_Y )  = 1+2.5A + 3W_1 -0.25A  W_1 + U_y\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\mathbb{I}$ is the indicator function equal to 1 if the statement in the brackets is true.\n",
    "\n",
    "<br/>\n",
    "\n",
    "In this particular data generating system (one of many compatible with our structural causal model), the expectation of the counterfactual outcome is a linear function of the treatment level $Y_a$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y_a] = \\mathbb{E}[1+2.5a + 3W_1 -0.25a  W_1 + U_y] =  \n",
    "$$\n",
    "\n",
    "$$\n",
    "1+2.5a + 3\\mathbb{E}[W_1] -0.25a \\mathbb{E}[W_1] + \\mathbb{E}[U_y] =\n",
    "$$\n",
    "\n",
    "$$\n",
    "1+2.5a + 3 \\underbrace{\\mathbb{E}[W_1]}_{0.6} -0.25a \\underbrace{\\mathbb{E}[W_1]}_{0.6} + \\underbrace{\\mathbb{E}[U_y]}_{0}\n",
    "$$\n",
    "\n",
    "\n",
    "$W_1$ is a random variable that specifies how students are grouped based on sociality.  \n",
    "\n",
    "$$P(W_1=1) = P(\\mathbb{I}(U_W <0.6)) = P(U_W < 0.6) = 0.6$$\n",
    "\n",
    "\n",
    "The expected value for $W_1$ is: \n",
    "\n",
    "$$\\mathbb{E}[W_1] = 1 * P(W_1=1) + 0 * P(W_1=0) = 0.6$$\n",
    "\n",
    "\n",
    "It means that 60% of students are social.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "45a37b711fb44300820ed87d064aff8d",
    "deepnote_cell_height": 231.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### STEP 5: Obtain the value of the target causal parameter (e.g, ATE): \n",
    "\n",
    "In this example, we can retrieve the ATE in a closed form from the SCM $\\mathfrak{C}$.\n",
    "\n",
    "The ATE value of our target causal parameter $Y$ is:\n",
    "\n",
    "$$\n",
    "ATE = \\mathbb{E}(Y(a=1) - Y(a=0)) = \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "= (1 + 2.5 \\cdot 1 + 3 \\cdot 0.6 - 0.25 \\cdot 1 \\cdot 0.6 + 0) - (1 + 2.5 \\cdot 0 + 3 \\cdot 0.6 - 0.25 \\cdot 0 \\cdot 0.6 + 0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 2.35\n",
    "$$\n",
    "\n",
    "\n",
    "The positive ATE means that the expected happiness $Y$ will be higher if all students drink beer compared to the scenario in which none drink beer. \n",
    "\n",
    "**BTW, this is just a made-up story.  Always drink responsibly! :-)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-5a760e85-9a35-4fe0-9d0d-de8a4b98b250",
    "deepnote_cell_height": 108.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Run the model in Python\n",
    "\n",
    "We translate the specific data generating process, which is an element of the causal\n",
    "model, into a Python simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00008-48a024a7-379d-4495-8da7-284b2ab18767",
    "deepnote_cell_height": 989,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     177
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5397,
    "execution_start": 1652974687818,
    "source_hash": "a4ef5a7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>W2</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.804414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.944055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.152629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.761524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W1  W2  A         Y\n",
       "0   1   1  0  3.804414\n",
       "1   0   0  0  0.969992\n",
       "2   0   2  1  3.944055\n",
       "3   1   1  0  4.152629\n",
       "4   1   3  1  5.761524"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_students = 5000\n",
    "\n",
    "\"\"\"Simulate the background factor\"\"\"\n",
    "\n",
    "#Exogenous variables\n",
    "Uw1 = np.random.uniform(low=0, high=1, size=n_students)\n",
    "Uw2 = np.random.binomial(n=1, p=0.5, size=n_students)\n",
    "Ua = np.random.normal(loc=-3, scale=1, size=n_students)\n",
    "Uy = np.random.normal(loc=0, scale=0.3, size=n_students)\n",
    "\n",
    "#Endogenous variables\n",
    "W1 = (Uw1 <= 0.6).astype(int)\n",
    "W2 = W1 + 2*Uw2\n",
    "A = (((1+W1+2*W2+Ua)) >= 0).astype(int)\n",
    "Y = 1 + 2.5*A + 3*W1 - 0.25*A*W1 + Uy\n",
    "\n",
    "\n",
    "# Store everything in a dataframe\n",
    "data = pd.DataFrame(data = \n",
    "                    {'W1': W1,\n",
    "                     'W2': W2,\n",
    "                     'A': A,\n",
    "                     'Y': Y})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we intervene on beer consumption parameter $A$ to generate the counterfactual outcomes $Y_0$ and $Y_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00010-555f0b7d-9e3c-4117-9e86-87ce38ed96f0",
    "deepnote_cell_height": 503,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     177
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 185,
    "execution_start": 1652974693234,
    "source_hash": "89135642"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1</th>\n",
       "      <th>W2</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.804414</td>\n",
       "      <td>6.054414</td>\n",
       "      <td>3.804414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969992</td>\n",
       "      <td>3.469992</td>\n",
       "      <td>0.969992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.944055</td>\n",
       "      <td>3.944055</td>\n",
       "      <td>1.444055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.152629</td>\n",
       "      <td>6.402629</td>\n",
       "      <td>4.152629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.761524</td>\n",
       "      <td>5.761524</td>\n",
       "      <td>3.511524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W1  W2  A         Y        Y1        Y0\n",
       "0   1   1  0  3.804414  6.054414  3.804414\n",
       "1   0   0  0  0.969992  3.469992  0.969992\n",
       "2   0   2  1  3.944055  3.944055  1.444055\n",
       "3   1   1  0  4.152629  6.402629  4.152629\n",
       "4   1   3  1  5.761524  5.761524  3.511524"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intervene on the beer consumption\n",
    "A = 1; Y1 = 1 + 2.5*A + 3*W1 - 0.25*A*W1 + Uy\n",
    "A = 0; Y0 = 1 + 2.5*A + 3*W1 - 0.25*A*W1 + Uy\n",
    "# Store results\n",
    "data['Y1'] = Y1\n",
    "data['Y0'] = Y0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-6cc92571-866c-4cb0-82ad-4c8d5daeb67e",
    "deepnote_cell_height": 74.78125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We notice that the outcome $Y$ when $A=0$ is equal to the counterfactual outcome $Y_0$. \n",
    "\n",
    "Likewise, the outcome $Y$ when $A=1$ is equal to the counterfactual outcome $Y_1$.\n",
    "\n",
    "Given input of the background factors $U$, the structural equations are deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00012-6e8ffd26-3433-41c4-b324-c1740c1b7c6b",
    "deepnote_cell_height": 136.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 26,
    "execution_start": 1652974693407,
    "owner_user_id": "6d4b6780-4c9b-422a-b280-80fd46703815",
    "source_hash": "57491638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.35005"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATE = (data['Y1'] - data['Y0']).mean()\n",
    "ATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of $ATE$ using our code is the same as what we calculated analytically. We got the same conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "caa1137eda4c4ea4bbf611fff7e1fb61",
    "deepnote_cell_height": 225.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "This chapter contents are highly inspired by the [Elements of Causal Inference (Open Access) book](https://mitpress.mit.edu/books/elements-causal-inference) by By Jonas Peters, Dominik Janzing and [Bernhard Schölkopf](https://www.is.mpg.de/~bs).\n",
    "\n",
    "We also used examples fom the [Introduction to Causal Inference course](https://www.ucbbiostat.com) by Maya L. Petersen & Laura B. Balzer, UC Berkeley.\n",
    "\n",
    "Bruno Gonçalves has a helpful [blog](https://medium.data4sci.com/causal-inference-part-iv-structural-causal-models-df10a83be580) on SEM too."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ca1c0dae-cfcc-4ea4-b356-eeedce5aaafd",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f82454df3ab4669350e470cecfad51160e6fdff8e76eafd19d8880dd92d922a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
