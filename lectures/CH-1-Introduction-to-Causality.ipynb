{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 - Introduction to Causality\n",
    "\n",
    "## Key Points Learned in the Chapter:\n",
    "\n",
    "### 1. Difference Between Causal and Statistical Inference:\n",
    "* The chapter highlights how causal inference differs from statistical inference by focusing on understanding cause-and-effect relationships rather than just identifying correlations.\n",
    "\n",
    "### 2. Historical Development of Causal Thinking:\n",
    "* The chapter covers the evolution of causal thinking, from **Aristotle's Four Causes** to **David Hume's empiricism**, and their impact on modern causal inference methods.\n",
    "\n",
    "### 3. Limitations of Observational Data:\n",
    "* It emphasizes the limits of using observational data alone to infer causal relationships, particularly in the presence of confounding variables.\n",
    "\n",
    "### 4. Importance of Interventions:\n",
    "* The role of **interventions** in distinguishing between correlation and causation is explored, with references to **Randomized Controlled Trials (RCTs)** as the gold standard for experimental design.\n",
    "\n",
    "### 5. Ladder of Causality:\n",
    "* The chapter introducesthe Judea Peral's **Ladder of Causality** and how we move from observations, to intervention to counterfactual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## 1.1. Introduction\n",
    "\n",
    "Our journey into the world of Applied Causal Inference begins here. In this chapter, we deal with fundamental questions about causality: \n",
    "\n",
    "\n",
    "- **What is causality?** \n",
    "- **How does causal inference differ from statistical inference?** \n",
    "- **In an age of remarkable machine learning achievements, why do we need causality?**\n",
    "\n",
    "\n",
    "Over the past decade, the landscape of data science and artificial intelligence has been transformed by the \"unreasonable effectiveness\" of machine learning algorithms. From computer vision systems that outperform humans in image recognition to natural language models capable of generating coherent, context-aware text, the capabilities of AI have grown exponentially. Models like *Claude Sonnet* and *ChatGPT* have not only revolutionized research but have also captured the public imagination, leading some to question the need for alternative approaches to data analysis.\n",
    "\n",
    "\n",
    "Indeed, if you've been following the rapid evolution of machine learning, you've likely encountered numerous examples of its prowess across various domains. This might prompt you to ask: *If these algorithms work so well, why should we bother looking into something else?*\n",
    "\n",
    "The answer lies in the unique insights and capabilities that causal inference offers. Despite the power of modern machine learning, there are scenarios where understanding the underlying causal mechanisms becomes crucial. \n",
    "\n",
    "In this chapter, we'll explore:\n",
    "\n",
    "- The historical development of causal thinking and its impact on scientific inquiry\n",
    "- Specific cases where causal models provide advantages over purely statistical methods\n",
    "- Common misconceptions and oversimplifications in causal reasoning\n",
    "\n",
    "By examining these aspects, we'll uncover why causal inference remains a critical tool in the data scientist's arsenal, complementing rather than competing with machine learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "## 1.2. A Brief History of Causality\n",
    "\n",
    "The concept of causality has been a cornerstone of human understanding across civilizations and throughout history. Its study has evolved significantly, shaping our approach to scientific inquiry and our understanding of the world around us.\n",
    "\n",
    "### Ancient Foundations: Aristotle's Four Causes\n",
    "\n",
    "In ancient Greece, Aristotle laid the groundwork for causal thinking that would influence Western philosophy for centuries. He posited that true knowledge of any process necessitates an understanding of its causal structure. Aristotle's framework included four types of causes:\n",
    "\n",
    "- **Material Cause**: The substance from which something is made\n",
    "- **Formal Cause**: The essential nature or form of the thing\n",
    "- **Efficient Cause**: The agent of change or the maker\n",
    "- **Final Cause**: The purpose or end for which something exists\n",
    "\n",
    "While this categorization may appear counterintuitive to modern scientists, it represents one of the earliest systematic attempts to categorize different aspects of causation. Aristotle argued that answering **why questions** forms the essence of scientific explanation.\n",
    "\n",
    "<img src=\"img/ch1/Aristotle_and_causal_thinking.png\" alt=\"Aristotle and Causal Thinking\" width=\"500\"/>\n",
    "\n",
    "\n",
    "BTW, what do you think about Aristotle picture?\n",
    "\n",
    "### The Enlightenment Shift: David Hume's Empiricism\n",
    "\n",
    "Fast forward to the 18th century, and we encounter David Hume, a Scottish philosopher who revolutionized causal thinking. Hume's approach marked a significant departure from Aristotelian ideas, focusing instead on empirical observation and human psychology.\n",
    "Hume's key insight was that we never directly observe cause-effect relationships in the world. Instead, we only experience the conjunction of events. As he famously wrote:\n",
    "\n",
    "\n",
    "\"We only find, that the one does actually, in fact, follow the other. The impulse of one billiard-ball is attended with motion in the second. This is the whole that appears to the outward senses.\" *(original spelling; Hume & Millican, 2007; originally published in 1739)*.\n",
    "\n",
    "\n",
    "Hume's theory of causality can be summarized as follows:\n",
    "\n",
    "- We observe sequences of events (e.g., object $A$ moves, then object $B$ moves.\n",
    "- Repeated observations of such sequences create an expectation in our minds.\n",
    "- This feeling of expectation is what we call **causality**.\n",
    "\n",
    "In essence, Hume argued that causality is not an inherent property of the world, but a psychological construct arising from our experiences.\n",
    "\n",
    "<img src=\"img/ch1/David_Hume_theory_of_causality_18th_century.png\" alt=\"Hume and Causal Theory\" width=\"500\"/>\n",
    "\n",
    "\n",
    "### Implications for Modern Causal Inference\n",
    "The historical evolution of causal thinking, from Aristotle to Hume, set the stage for modern approaches to causal inference. These early philosophers wrestled with fundamental questions that still resonate today:\n",
    "\n",
    "- How can we distinguish genuine causal relationships from mere correlations?\n",
    "- To what extent can we infer causal structures from observational data alone?\n",
    "- What role does human cognition play in our understanding of causality?\n",
    "\n",
    "As we delve deeper into methods of causal inference, it's crucial to remember that we're building upon centuries of philosophical and scientific thought. The challenges we face in identifying and quantifying causal relationships echo those pondered by thinkers throughout history.\n",
    "\n",
    "Here are some of the main contemporary theorists of causal inference, along with their key contributions and primary academic affiliations:\n",
    "\n",
    "**[Judea Pearl](https://bayes.cs.ucla.edu/jp_home.html)**, Professor Emeritus, Department of Computer Science, University of California, Los Angeles (UCLA)\n",
    "*Key Contribution*: Developed causal diagrams (DAGs) and do-calculus, laying the groundwork for modern approaches to causal inference, particularly in distinguishing correlation from causation.\n",
    "\n",
    "**[Donald Rubin](https://statistics.fas.harvard.edu/people/donald-b-rubin)**, Professor Emeritus, Department of Statistics, Harvard University\n",
    "*Key Contribution*: Creator of the Rubin Causal Model (RCM) or potential outcomes framework, which is central to the analysis of causal effects, particularly in the context of randomized and observational studies.\n",
    "\n",
    "**[James Heckman](https://cehd.uchicago.edu/?page_id=71)**, Professor of Economics, University of Chicago\n",
    "*Key Contribution*: Significant contributions to econometrics, including the Heckman correction for addressing selection bias and the estimation of treatment effects in observational data.\n",
    "\n",
    "**[Guido Imbens](https://www.gsb.stanford.edu/faculty-research/faculty/guido-w-imbens)**, Professor of Economics, Stanford University\n",
    "*Key Contribution*: Known for work on instrumental variables and local average treatment effects (LATE), providing practical methods for estimating causal effects in both observational and quasi-experimental contexts.\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 What babies are telling us about Causality\n",
    "\n",
    "While Hume's theory of causation provided a foundational understanding of cause and effect, it left some questions unanswered. To address these gaps, we turn to an unexpected source: human babies. The study of how babies develop their understanding of the world offers profound insights into the nature of causal reasoning and its importance in human cognition.\n",
    "\n",
    "<img src=\"img/ch1/baby_learning_brain.png\" alt=\"Baby and Learning\" width=\"500\"/>\n",
    "\n",
    "\n",
    "### Beyond Passive Observation: The Active Learner\n",
    "\n",
    "Alison Gopnik, a developmental psychologist, has made significant contributions to our understanding of how children construct their models of the world. Her work, bridging developmental psychology and computer science, reveals that children are far more than passive observers of their environment [Gopnik,(2012)](https://doi.org/10.1126/science.1223416).\n",
    "\n",
    "Key insights from Gopnik's research include:\n",
    "\n",
    "1. **Children as Scientists**: Babies and young children engage in behaviors that, while sometimes interpreted as disruptive or random, are actually systematic experiments to understand their environment [Gopnik,(2009)](https://books.google.no/books/about/The_Philosophical_Baby.html).\n",
    "\n",
    "2. **Preference for the Unpredictable**: Infants as young as 11 months show a preference for objects that behave in unpredictable ways. This preference drives them to explore and learn about novel phenomena efficiently [Stahl,(2015)](https://doi.org/10.1126/science.aaa3799).\n",
    "\n",
    "3. **Active Interaction**: Unlike Hume's theory, which focuses on passive observation, babies actively interact with their environment to test hypotheses and build causal models.\n",
    "\n",
    "\n",
    "### The Power of Intervention\n",
    "\n",
    "What sets the infant's approach apart from Hume's conception is the crucial element of intervention. In the context of causal inference, these interactions are termed **interventions**, and they form the backbone of modern experimental design [Pearl,(2009)](https://doi.org/10.1017/CBO9780511803161).\n",
    "\n",
    "\n",
    "Interventions allow us to:\n",
    "\n",
    "- Distinguish between correlation and causation\n",
    "- Test hypotheses about causal relationships\n",
    "- Build more robust and accurate models of the world\n",
    "\n",
    "This concept of intervention is not just a part of infant behavior; it's at the heart of scientific inquiry. The gold standard of scientific experimentation, the **Randomized Controlled Trial (RCT)**, is essentially a formalized, rigorous application of the same principle that drives a baby to repeatedly drop a spoon from their high chair [5].\n",
    "\n",
    "\n",
    "### Implications for Causal Inference\n",
    "\n",
    "The insights from developmental psychology have profound implications for how we approach causal inference:\n",
    "\n",
    "1. **Active Learning**: We should design algorithms and studies that don't just passively observe data but actively interact with systems to uncover causal structures [6].\n",
    "\n",
    "2. **Embracing Uncertainty**: Like infants who are drawn to unpredictable phenomena, our causal inference methods should be capable of identifying and exploring areas of uncertainty [7].\n",
    "\n",
    "3. **Iterative Experimentation**: The scientific process, mirroring a child's repeated experiments, should involve iterative interventions and observations to refine our causal models [8].\n",
    "\n",
    "As we delve deeper into the methods and applications of causal inference in subsequent chapters, keep in mind this fundamental insight: *true understanding of Causality comes not just from observing the world, but from interacting with it*. This principle, so naturally embodied in the behavior of infants, forms the cornerstone of modern causal inference techniques and experimental design.\n",
    "\n",
    "<div style=\"color:blue\">\n",
    "<b>How can we, as researchers, approach the world of science with the same curiosity, experimentation, and openness to uncertainty that babies use to understand their world, and how might this change the way we design our studies and algorithms?\n",
    "</div>\n",
    "    \n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fa524251-c07c-44c7-89a2-0fbaa27f6617",
    "deepnote_cell_height": 6039.234375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1.4. Anything wrong with data science?\n",
    "\n",
    "Let's start with a simple image (Courtesy of Markus Elsholz). \n",
    "What is the object in the image below? A chair, right?\n",
    "\n",
    "![img](img/ch1/Beuchet_chair_a.png)\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "What if we look at the object from a different angle? \n",
    "\n",
    "![img](img/ch1/Beuchet_chair_b.png)\n",
    "\n",
    "\n",
    "The object is not a chair! We just had an illusion of a chair if the parts are viewed from a single and specific angle. This is the **Beuchet chair experiment** on changing perception in observations.\n",
    "\n",
    "\n",
    "<div style=\"color:blue\">\n",
    "<b>Do you have any other example?\n",
    "</div>\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "Unfortunately, most of our works in statistics, data science, and machine learning are based on **observations**! However, we can not just rely on observations to model and understand our world. \n",
    "\n",
    "![img](img/ch1/Math_Learning.jpeg)\n",
    "\n",
    "\n",
    "Saying that, let's see what Causality is or is NOT.\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "## 1.5. What is NOT Causality?\n",
    "\n",
    "<br/><br/>\n",
    "### Causality is not Algebra\n",
    "\n",
    "Dario is a little boy that feels fever, so his Mom measures his temperature with a thermometer. Then, hopefully, he can skip school today. \n",
    "From an algebra point of view, the height of mercury $X$ in the pipe is related to Dario's body temperature $Y$ with a constant $k$. \n",
    "\n",
    "$Y = k * X$\n",
    "\n",
    "<img src=\"img/ch1/little-sick-boy.jpeg\" width=\"250\"/>\n",
    "\n",
    "For our algebra equation, it does not matter if Dario's body temperature increases the mercury column height or the other way.\n",
    "\n",
    "<br/><br/>\n",
    "### Causality is not Statistics\n",
    "\n",
    "- Most scientific inquiry/data analyses have one of the two goals:\n",
    "\n",
    "    - **Association/prediction**, i.e., determine predictors or variables associated with the outcome of interest.\n",
    "    - **Causality**, i.e., understanding factors that cause or influence the outcome of interest.\n",
    "\n",
    "- Statistical concepts are those expressible in terms of the joint distribution of observed variables.\n",
    "\n",
    "- We are often told that **association is not causation!** However, we forget about it. Therefore, we see numerous spurious/funny correlations like examples in the [Spurious Correlations collection](https://tylervigen.com/spurious-correlations). \n",
    "\n",
    "![img](img/ch1/Spurious_Correlations_Muzzarella.png)     \n",
    "\n",
    "<br/><br/>\n",
    "Another example is related to cigarette commercials in the USA in the 50th that claim smoking is helpful for coughs treatment and even helps you have a more fit body!\n",
    "\n",
    "![img](img/ch1/Cigarette_Commercials.png)  \n",
    "\n",
    "<br/><br/>\n",
    "### Causality is not Machine Learning\n",
    "\n",
    "* We hear about rapid advances in machine learning systems every day, such as deep-learning algorithms in self-driving cars, speech-recognition systems, image processing, virtual reality, and LLMs. Nevertheless, deep learning has succeeded primarily by performing repeatable tasks to answer specific questions that we thought were difficult. But, those questions are not that difficult. \n",
    "\n",
    "\n",
    "* Machine learning has not addressed the tough questions that prevent us from achieving human-level AI. The public believes that AI machines can think like humans. In reality, computers don't even have animal-like cognitive abilities yet. See [Gary Marcus's paper, The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence.](https://arxiv.org/pdf/2002.06177). \n",
    "\n",
    "\n",
    "* The field of artificial intelligence is **bursting with micro discoveries**—the sort of things that make good press releases—but machines are still disappointingly far from human-like cognition. See [Gary Marcus's book, Rebooting AI: Building Machines We Can Trust](http://garymarcus.com/index.html)\n",
    "\n",
    "![img](img/ch1/ML_Animal_Abilities.png)  \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "Machine learning is trapped in the **Plato Cave**. See [Judea Pearl's book, the Book of Why](http://bayes.cs.ucla.edu/WHY/). \n",
    "\n",
    "\n",
    "![img](img/ch1/Plato_Cave.jpeg)  \n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "Followings are some shortcomings of machine learning when it comes to causal inference. \n",
    "\n",
    "- Machine learning is limited to transferability to new problems and any form of generalization to data with a different distribution. \n",
    "\n",
    "- Machine learning often disregards information that even animals use heavily, e.g., interventions, domain shifts, and temporal structure. \n",
    "\n",
    "- Most current successes of machine learning boil down to large-scale pattern recognition on suitably collected independent and identically distributed (i.i.d.) data which is not the case in reality!\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "## 1.6. Going Beyond Machine Learning to Answer a Different Kind of Questions\n",
    "\n",
    "Now, we explore three types of questions that machine learning and causal inference address: prediction, counterfactual (what-if), and causal questions.\n",
    "\n",
    "### 1. Prediction Questions:\n",
    "Machine Learning excels at answering prediction-based questions. As highlighted in the book *Prediction Machines*, \"the new wave of artificial intelligence does not bring us intelligence but instead a critical component of intelligence—prediction.\" We can do remarkable things with machine learning, provided that we frame our problems as prediction problems, where the focus is on predicting outcomes based on historical data.\n",
    "\n",
    "- **Example Questions**:\n",
    "  <div style=\"color:blue\">\n",
    "  - Can we predict customers choices based on their previous behavior?<br>\n",
    "  - Can we forecast next quarter’s sales using historical sales data?\n",
    "  </div>\n",
    "\n",
    "### 2. Counterfactual (What-If) Questions:\n",
    "Machine Learning, while powerful in prediction tasks, struggles with counterfactual reasoning—answering \"what if\" questions that require exploring alternate realities. Machine learning models tend to fail when data deviates from the training distribution, making them poor at handling inverse causality or what-if scenarios.\n",
    "\n",
    "- **Example Questions**:\n",
    "  <div style=\"color:blue\">\n",
    "  - What would happen to website traffic if we redesigned our homepage?<br>\n",
    "  - What if we reduced product prices by 10%—how would sales change?\n",
    "  </div>\n",
    "\n",
    "### 3. Causal Questions:\n",
    "At the heart of these types of questions is a causal inquiry—we want to know not just *what* happens but *why* it happens. Causal questions are central to real-world decision-making, from business strategies to personal life choices. Unfortunately, we can't rely on machine learning's correlations to answer these causal questions; instead, we need causal inference techniques to uncover these deeper insights.\n",
    "\n",
    "- **Example Questions**:\n",
    "  <div style=\"color:blue\">\n",
    "  - Does increasing training hours improve employee performance?<br>\n",
    "  - Does advertising on social media lead to more product sales?\n",
    "  </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. What is Causality?\n",
    "\n",
    "To understand causality, let's first revisit the fundamentals of **statistical inference** and then contrast it with **causal inference**.\n",
    "\n",
    "### Traditional Statistical Inference Paradigm\n",
    "\n",
    "Statistics summarize a population/set/observation into a distribution based on samples drawn from that population. Remember that we cannot derive causal claims from observational data alone.\n",
    "\n",
    "Causal inference is the scientific process in which **cause-and-effect** relationships are inferred from observational data, but only after assuming a **causal model** that drives the relationships between random variables. \n",
    "\n",
    "We use an analogy proposed initially by [Judea Pearl, 2016](http://bayes.cs.ucla.edu/jsm-august2016-bw.pdf) and later used by [Camilo Hurtado, 2017](https://repositorio.unal.edu.co/handle/unal/59495) to better explain causal inference. \n",
    "\n",
    "- We assume an unknown, invariant, and true data-generating process, $M$, that produces a set of observed random variables (data), $D$, and associated multivariate probability distribution, $P$. \n",
    "- The target of scientific inquiry in traditional statistical analysis is a probabilistic quantity, $Q(P)$, which summarizes some attribute of $D$ that is of interest.\n",
    "- $Q(P)$ can be estimated from $P$ and $D$ alone. \n",
    "\n",
    "![img](img/ch1/Stat_Paradigm.png)\n",
    "\n",
    "### Causal Inference Paradigm\n",
    "\n",
    "Causal analysis differs from statistical analysis. Causal inference is interested in the effect of an **intervention (treatment)** on the causal system $M$ when experimental conditions change. \n",
    "\n",
    "- This **intervention** acts as a specific modification to the data-generating model $M$, leading to an **unobserved (counterfactual) set of data $D'$ and a distribution $P'$**. This change is known as the **causal effect of an intervention**. \n",
    "- In other words, changes in the data-generating process $M$ generate hypothetical (unobserved) $D'$ and $P'$. \n",
    "- Then, a causal target parameter $Q(P')$ is computed, which summarizes the causal effect of the given intervention (or treatment). \n",
    "\n",
    "![img](img/ch1/Causal_Paradigm.png)\n",
    "\n",
    "### The Challenge:\n",
    "\n",
    "- The problem is that we only have access to $D$ and therefore $P$ in observational studies, while $D'$ and $P'$ remain unknown. Thus, $D$ or $P$ alone cannot answer the causal quantity of interest. \n",
    "- We use a set of **(un)testable causal assumptions** to estimate $Q(P')$ from $D$ and $P$.\n",
    "- With these assumptions at hand, we can mathematically express $Q(P')$ in terms of both $D$ and $P$, leaving $D'$ and $P'$ out.\n",
    "\n",
    "### Causality Goes Beyond Statistics\n",
    "\n",
    "- Causal inference requires extra information. The distribution of the data alone cannot tell us how it would change under new conditions.\n",
    "- To make causal inferences, we must make **causal assumptions** about the processes that generated the data. These assumptions are not statistical.\n",
    "\n",
    "\n",
    "### Two Schools of Thought for Inference:\n",
    "\n",
    "- **Associational Inference**: Includes any relationship that can be defined in terms of the joint distribution of observed variables\n",
    "    - Correlation, conditional independence, dependence, likelihood, confidence level...\n",
    "    - Testable in principle\n",
    "\n",
    "- **Causal Inference**: Includes any relationship that cannot be defined in terms of the joint distribution alone\n",
    "    - Randomization, confounding, mediation, attribution, effect...\n",
    "    - Not testable in principle (without experimental control)\n",
    "    - Only testable if we can intervene and see what happens.\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Statistical inference** focuses on identifying patterns and relationships within the data but does not allow for causal claims.\n",
    "- **Causal inference** requires making assumptions about how interventions would alter the data-generating process, going beyond statistical relationships.\n",
    "- Causal models help us predict what would happen under hypothetical scenarios, providing insights into the \"why\" behind the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Causality Ladder\n",
    "\n",
    "In the [Book of Why](http://bayes.cs.ucla.edu/WHY/), Judea Pearl suggested the **Ladder of Causation**, which represents three levels of causality with different organisms at each level. \n",
    "\n",
    "* **Association (Rung One)**: This level deals with observing relationships between variables. Here, we can predict how one event affects our belief in another. For example, observing a SpaceX launch may increase our belief that SpaceX stock will rise. The primary activity here is **observation**.\n",
    "\n",
    "* **Intervention (Rung Two)**: At this level, we move beyond observation to actively intervening in a system. By changing one variable, we can see its effect on another, much like performing an experiment. For instance, going to bed earlier could result in more energy the next day. The activity here is **doing** or **intervening**.\n",
    "\n",
    "* **Counterfactual Reasoning (Rung Three)**: This level involves imagining alternative scenarios and understanding what would have happened under different conditions. It allows us to ask \"what if\" questions, such as whether you would have arrived on time had you taken the train instead of the car. The activity here is **imagining** or **understanding alternate outcomes**.\n",
    "\n",
    "![img](img/ch1/Causal_Ladder.png)\n",
    "\n",
    "<br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-1b357484-1425-412d-abc8-5a53506c4d3d",
    "deepnote_cell_height": 189.5625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1.9. The Danger of Oversimplification\n",
    "\n",
    "In our quest to understand causality, it's crucial to address a common pitfall: the temptation to oversimplify.\n",
    "\n",
    "* **Human Intuition vs. Complex Reality**: While simple models are more appealing to human intuition, they often fail to capture the intricacies of complex systems. This is precisely why we rely on statistics and advanced causal inference methods.\n",
    "  \n",
    "* **The Need for Justified Models**: Before adopting simpler models, we must ensure they are justified by expert knowledge or thorough analysis. Simplicity should not come at the cost of accuracy or completeness.\n",
    "  \n",
    "* **Misinformation Risk**: Oversimplification can lead to misinformation. In causal inference, this is particularly dangerous as it may result in incorrect conclusions about cause-effect relationships.\n",
    "  \n",
    "* **Balancing Simplicity and Accuracy**: The challenge lies in finding the right balance between model simplicity and accurate representation of causal relationships. This balance is crucial for both understanding and practical application.\n",
    "\n",
    "Oversimplification in causal inference can lead to misleading conclusions. Always strive for models that are as simple as possible, but no simpler than the complexity of the system under study requires.\n",
    "\n",
    "\n",
    "Further Reading and Media on Oversimplification:\n",
    "\n",
    "**Book**: [Thinking, Fast and Slow](https://www.goodreads.com/book/show/11468377-thinking-fast-and-slow) by Daniel Kahneman, 2011, explores various cognitive biases, including our tendency to prefer simple explanations over complex ones.\n",
    "\n",
    "**Book**: [How Not To Be Wrong, The Power Of Mathematical Thinking](https://www.jordanellenberg.com/book/how-not-to-be-wrong/) by Jordan Ellenberg, 2014, connects various economic and societal philosophies with basic mathematics and statistical principles. \n",
    "\n",
    "**Podcast**: The \"[How we transferred our biases into our machines and what we can do about it](https://youarenotsosmart.com/2017/11/20/yanss-115-how-we-transferred-our-biases-into-our-machines-and-what-we-can-do-about-it/)\" episode from the podcast \"You Are Not So Smart\". This episode discusses how our tendency to oversimplify can lead to biases in machine learning and AI systems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10. Causal Inference in Business: The Promise of Causal AI\n",
    "This section inspired by the [Causal Artificial Intelligence](https://www.oreilly.com/library/view/causal-artificial-intelligence/9781394184132/) book by Hurwitz & Thompson, 2023.\n",
    "\n",
    "\n",
    "### The Limitations of Traditional Data Analysis\n",
    "Over the past decade, the prevailing trend in data science has been the mantra of \"more data is better.\" Organizations invested heavily in data collection, assuming that the sheer volume of information would inevitably lead to more profound insights and improvements in business performance. However, this data-centric approach has its limitations:\n",
    "\n",
    "* **Correlation vs. Causation**: While traditional analysis can identify correlations, it often struggles to differentiate them from true causal relationships.\n",
    "* **Data Overload**: Simply gathering more data does not guarantee better insights, especially if the underlying business questions are not well-posed.\n",
    "* **Lack of Context**: Data-driven approaches often miss the critical contextual knowledge that domain experts can provide, leading to incomplete or misleading conclusions.\n",
    "\n",
    "### The Causal AI Advantage\n",
    "Causal AI offers a solution to these limitations by combining causal inference techniques with the predictive power of AI models. The key benefits of Causal AI for businesses include:\n",
    "\n",
    "* **Understanding 'Why'**: Instead of merely forecasting what may happen, Causal AI seeks to uncover why events occur, leading to interventions that target root causes rather than symptoms.\n",
    "* **Enhanced Decision Making**: By understanding causal relationships, organizations can make better decisions about resource allocation and strategic planning.\n",
    "* **Robust Predictions**: Causal models tend to be more resilient to changes in external conditions, making them particularly useful in dynamic and uncertain business environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "768600bfea1a4cbb81ed3db277469651",
    "deepnote_cell_height": 301.734375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Acknowledgement\n",
    "\n",
    "Most of the ideas in this chapter are taken from Judea Pearl Books. \n",
    "\n",
    "* [Causality, 2nd Edition](http://bayes.cs.ucla.edu/BOOK-2K/)\n",
    "* [The Book of Why](http://bayes.cs.ucla.edu/WHY/)\n",
    "\n",
    "We also like to reference the open-source book on causality by Matheus Facure Alves. He did a great job in explaining causal concepts with examples and fuuny memes.\n",
    "\n",
    "* [Causal Inference for The Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ca97ebbe-c21a-477a-b9d8-e5669467789a",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
