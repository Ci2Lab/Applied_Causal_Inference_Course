{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fa524251-c07c-44c7-89a2-0fbaa27f6617",
    "deepnote_cell_height": 9278.578125,
    "deepnote_cell_type": "markdown",
    "owner_user_id": "a91a2c6a-0c99-4421-a773-926bd3919ed9"
   },
   "source": [
    "# Chapter 1 - Introduction to Causality\n",
    "\n",
    "\n",
    "## Anything wrong with data science?\n",
    "\n",
    "Let's start with a simple image. What is the object in the image below? A chair, right?\n",
    "\n",
    "![img](img/ch1/Beuchet_chair_a.png)\n",
    "\n",
    "\n",
    "What if we look at the object from a different angle? \n",
    "\n",
    "![img](img/ch1/Beuchet_chair_b.png)\n",
    "\n",
    "The object is not a chair! We just had an illusory percept of a chair if the parts are viewed from a single, very special vantage point (Image courtesy of Markus Elsholz.) This is the Beuchet chair experiment on changing perception in observations.\n",
    "\n",
    "\n",
    "Unfortunately, most of our works in statistics, data science, and machine learning are based on **observations**! We can not just rely on observations to model and understand our systems. \n",
    "Last but not least, math and statistics have been useful since forever, and it is unlikely it will stop now. So, learn what makes your work valuable and useful, not the latest shining machine learning tool that no one figured out how to use. Knowledge in Math and Statistics is valuable precisely because they are hard to acquire. \n",
    "\n",
    "![img](img/ch1/Math_Learning.jpeg)     \n",
    "\n",
    "\n",
    "Saying that, let's see what Causality is or is NOT.\n",
    "\n",
    "\n",
    "## What is NOT Causality?\n",
    "\n",
    "### Causality is not Algebra\n",
    "\n",
    "Dario is a little boy that feels fever, so his Mom measures his temperature with a thermometer. Then, hopefully, he can skip school today. \n",
    "From an algebra point of view, the height of mercury $X$ in the pipe has a linear relation to Dario's body temperature $Y$ with a constant $k$. \n",
    "\n",
    "$Y = k * X$\n",
    "\n",
    "<img src=\"img/ch1/little-sick-boy.jpeg\" width=\"250\"/>\n",
    "\n",
    "For our algebra equation does not matter Dario's body temperature increase the mercury column height or the other way.\n",
    "\n",
    "### Causality is not Statistics\n",
    "\n",
    "- Most scientific inquiry/data analyses have one of the two goals:\n",
    "    - **Association/prediction**, i.e., determine predictors or variables associated with the outcome of interest.\n",
    "    - **Causality**, i.e., understanding factors that cause or influence the outcome of interest.\n",
    "\n",
    "- Statistical concepts are those expressible in terms of the joint distribution of observed variables.\n",
    "\n",
    "- We are often told that association is not causation. \n",
    "\n",
    "However, we forget about it. Therefore, we see numerous spurious/funny correlations like examples in the [Spurious Correlations collection](https://tylervigen.com/spurious-correlations). \n",
    "\n",
    "![img](img/ch1/Spurious_Correlations_Muzzarella.png)     \n",
    "\n",
    "Another example is related to cigarette commercials in the USA in the 50th that claim smoking is helpful for coughs treatment and even helps you have a more fit body!\n",
    "\n",
    "![img](img/ch1/Cigarette_Commercials.png)  \n",
    "\n",
    "\n",
    "### Causality is not Machine Learning\n",
    "\n",
    "We hear about rapid advances in machine learning systems almost every day, such as deep-learning algorithms in self-driving cars, speech-recognition systems, image processing, and virtual reality. Nevertheless, deep learning has succeeded primarily by performing repeatable tasks to answer specific questions that we thought were difficult. But, those questions are not that difficult. \n",
    "\n",
    "Machine learning has not addressed the tough questions that prevent us from achieving human-level AI. The public believes that AI machines can think like humans. In reality, computers don't even have animal-like cognitive abilities yet. See Adnan Darwiche's paper [Human-Level Intelligence or Animal-Like Abilities?](https://arxiv.org/abs/1707.04327). \n",
    "\n",
    "> The field of artificial intelligence is \"bursting with micro discoveries\"—the sort of things that make good press releases—but machines are still disappointingly far from human-like cognition.--Gary Marcus, New York University\n",
    "\n",
    "![img](img/ch1/ML_Animal_Abilities.png)  \n",
    "\n",
    "Machine learning systems usually operate in complex environments governed by rich webs of causal relations while having only access to surface representations of those causal relations through observation and measurements. Medicine, economics, education, climatology, and politics are typical examples of such environments. In other words, machine-learning methods today provide us with an efficient way of going from finite sample estimates to probability distributions. However, we still need to move from distributions to cause-effect relations in the real world [From the Book of Why](http://bayes.cs.ucla.edu/WHY/). Machine learning is trapped in the Plato cave.\n",
    "\n",
    "\n",
    "![img](img/ch1/Plato_Cave.jpeg)  \n",
    "\n",
    "\n",
    "Followings are some shortcomings of machine learning when it comes to causal inference. \n",
    "\n",
    "- Machine learning is limited to transferability to new problems and any form of generalization to data with a different distribution. \n",
    "\n",
    "- Machine learning often disregards information that even animals use heavily, e.g., interventions, domain shifts, and temporal structure. \n",
    "\n",
    "- Most current successes of machine learning boil down to large-scale pattern recognition on suitably collected independent and identically distributed (i.i.d.) data which is not the case in reality!\n",
    "\n",
    "\n",
    "## Going Beyond Machine Learning to Answer a Different Kind of Questions\n",
    "\n",
    "Machine Learning is currently very good at answering **prediction kinds of questions**. As the authors put it in the book Prediction Machines, \"the new wave of artificial intelligence does not bring us intelligence but instead a critical component of intelligence - prediction.\" We can do all sorts of fantastic things with machine learning. The only requirement is that we frame our problems as prediction problems. \n",
    "\n",
    "- Do we want to translate from English to Italian? Then we build an ML model that predicts Italian sentences when given English sentences. \n",
    "- Do we want to recognize human faces? Then we build an ML model that predicts the presence of a human face in a subsection of a picture. \n",
    "\n",
    "An ML algorithm can wonder under very strict boundaries, and it fails miserably if our used data deviates a little from what the model has been trained before. ML is notoriously poor at this inverse causality type of problem that requires us to answer **what if** questions or **counterfactuals**. \n",
    "\n",
    "- What would happen if I used another price instead of this price I'm currently asking for my merchandise? \n",
    "- - What would happen if, instead of this low-fat diet I'm in, I do a low-sugar one? \n",
    "What would happen if we used a different system instead of our current education system?\n",
    "\n",
    "At the heart of these questions, there is a causal inquiry we wish to know the answer to. **Causal Questions** permeate everyday problems, like figuring out how to make sales go up. Still, they also play an important role in very personal and dear dilemmas: \n",
    "\n",
    "- Do I have to go to an expensive school to be successful in life (does education cause earnings)? \n",
    "- Does the public healthcare system increase life expectancy? \n",
    "\n",
    "Unfortunately for ML, we can't rely on correlation-type predictions to answer causal questions. Answering this kind of question is more challenging than most people appreciate. Your teachers have probably repeated to you that \"association is not causation\" and \"association is not causation.\" This is what this course is all about. \n",
    "\n",
    "![img](img/ch1/Courtroom.png)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "681a415d-d513-41b0-bd5a-9eea5b588413",
    "deepnote_cell_height": 3880.25,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## What is Causality?\n",
    "\n",
    "### Traditional Statistical Inference Paradigm\n",
    "\n",
    "To explain causality, we go back to statistics fundamentals. Statistics summarize a population/set/observation into a distribution based on samples drawn from that population. Remember that we cannot derive causal claims from observational data alone.\n",
    "\n",
    "Causal inference is the scientific process in which cause-and-effect relationships are inferred from observational data, but only after assuming a **causal model** that drives the relationships between random variables. \n",
    "\n",
    "We used an analogy proposed initially by [Judea Pearl, 2016](http://bayes.cs.ucla.edu/jsm-august2016-bw.pdf) and later used by [Camilo Hurtado, 2017](https://repositorio.unal.edu.co/handle/unal/59495) to better explain the causal inference. We assume an unknown, invariant, and true data generating process, $M$, generates a set of observed random variables (data), $D$, and associated multivariate probability distribution, $P$. \n",
    "The target of scientific inquiry in traditional statistical analysis is a probabilistic quantity, $Q(P)$, which summarizes some attribute of $D$ that is of our interest. $Q(P)$ can be estimated from $P$ and $D$ alone. \n",
    "\n",
    "![img](img/ch1/Stat_Paradigm.png)\n",
    "\n",
    "However, causal analysis is different from statistical analysis. Causal inference is interested in an external intervention (treatment) effect on the causal system $M$ when experimental conditions change. This **intervention** acts as a specific modification to the data-generating model $M$, leading to an **unobserved (counterfactual) set of data $D'$ and a distribution $P'$**. This change is known as the **causal effect of an intervention**. In other words, it is the changes in the data generating process $M$ that generate hypothetical (unobserved) $D'$ and $P'$. Then, a causal target parameter $Q(P')$ is computed, which summarizes the causal effect of the given intervention (or treatment). \n",
    "\n",
    "![img](img/ch1/Causal_Paradigm.png)\n",
    "\n",
    "The problem is that we only have access to $D$ and therefore $P$ in observational studies, while $D'$ and $P'$ remain unknown. Therefore, $D$ or $P$ alone cannot answer the causal quantity of interest. That is why we use a set of (un)testable causal assumptions to estimate $Q(P')$ from $D$ and $P$. With these assumptions at hand; we can mathematically express $Q(P')$ in terms of both $D$ and $P$, leaving $D'$ and $P'$ out.\n",
    "\n",
    "### Causality is Beyond Statistics\n",
    "\n",
    "- Causal inference requires extra information. There is nothing in the distribution of the data alone that tells us how it should change when conditions change.\n",
    "- To make causal inferences we must make **assumptions** about the processes that generated the data. These are not statistical assumptions.\n",
    "- **Causal assumptions** come from the expertise and previous experience of the researcher.\n",
    "- **Causal questions** are questions about what happens when we change the way data are generated.\n",
    "\n",
    "\n",
    "To summarize, we have two schools of thought for inference:\n",
    "\n",
    "- **Associational Concept:** any relationship that can be defined in terms of a joint distribution of observed variables\n",
    "    - Correlation, conditional independence, dependence, likelihood, confidence level…\n",
    "    - Testable in principle\n",
    "\n",
    "- **Causation Concept:** any relationship that cannot be defined in terms of this distribution alone\n",
    "    - Randomization, confounding, mediation, attribution, effect, …\n",
    "    - Not testable in principle (without experimental control)\n",
    "    - we can only test them if we can intervene on the system and see what happens. Even if we can intervene, there are some complications. But there are some tricks…\n",
    "\n",
    "\n",
    "### Causality Ladder\n",
    "\n",
    "In the [Book of Why](http://bayes.cs.ucla.edu/WHY/), Judea Pearl suggested the **Ladder of Causation**, which represents three levels of causality with different organisms at each level. \n",
    "* Most animals and present-day learning machines are on the first level, learning from the association. \n",
    "* Tool users, such as early humans, are on the second level if they act by planning and not merely by imitation. We can also use experiments to learn the effects of interventions, and presumably, this is how babies acquire much of their causal knowledge. \n",
    "* Finally, on the top level, counterfactual learners can imagine worlds that do not exist and infer reasons for observed phenomena. \n",
    "\n",
    "![img](img/ch1/Causal_Ladder.png)\n",
    "\n",
    "### History of Causal Inference\n",
    "\n",
    "* \"I would rather learn one causal law than be King of Persia.”, Democritus\n",
    "* “material, formal, efficient, and final are four causes of behavior”, Aristotle \n",
    "* A comparison trial is mentioned in the book of Daniel.\n",
    "* Hume’s cause and effect analogy. \n",
    "* Lindt's clinical trial to cure scurvy with lemon.\n",
    "* Wright's path analysis, Neyman's potential outcomes.\n",
    "* Haavelmo's structural equations.\n",
    "* Modern methods: Rubin, Robins, Pearl, Spirtes, Glymour.\n",
    "* Today: many papers in UAI, NIPS, ICML Conference/journal papers.\n",
    "\n",
    "![img](img/ch1/Causality_History.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-1b357484-1425-412d-abc8-5a53506c4d3d",
    "deepnote_cell_height": 189.59375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Chapter's Key Ideas\n",
    "\n",
    "So far, we've seen that association is not causation. Most importantly, we've seen precisely what causality is and is not  We've also mentined to the history of causal inference.\n",
    "\n",
    "Moving forward, we will see some of the basic techniques to estimate causal effect, starting with the golden standard of a randomised trial. We'll also review some statistical concepts as we go. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "768600bfea1a4cbb81ed3db277469651",
    "deepnote_cell_height": 301.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "Most of the ideas in this chapter are taken from Judea Pearl Books. \n",
    "\n",
    "* [Causality, 2nd Edition](http://bayes.cs.ucla.edu/BOOK-2K/)\n",
    "* [The Book of Why](http://bayes.cs.ucla.edu/WHY/)\n",
    "\n",
    "We also like to reference the open-source book on causality by Matheus Facure Alves. He did a great job in explaining causal concepts with examples and fuuny memes.\n",
    "\n",
    "* [Causal Inference for The Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)\n",
    "\n",
    "[Ilya Shpitser](https://www.cs.jhu.edu/~ilyas/) from JHU also did a great job with his causal inference course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e9f789e8-0475-4790-a085-15ec7f70f6c3' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ca97ebbe-c21a-477a-b9d8-e5669467789a",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
