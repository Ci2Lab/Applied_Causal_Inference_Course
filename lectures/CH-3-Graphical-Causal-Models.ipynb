{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6c5bf2a9-480b-448f-bc9f-84ff3ed37c21",
    "deepnote_cell_height": 729.421875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Chapter 3: Graphical Causal Models\n",
    "\n",
    "## Thinking About Causality with Graphs\n",
    "\n",
    "Graphical models are the language of causality. A causal graphical model is a way to represent how causality works in terms of what causes what.\n",
    "\n",
    "\n",
    "**Example: the effect of a medicine on an ill patient**\n",
    "\n",
    "If only severely sick patients get the drug, it might even look like giving the drug decreases their health. That is because the severe sickness symptoms are getting mixed up with the drug's effect.\n",
    "If we break down the patients into severe and not severe groups and analyze the drug impact in each subgroup, we will get a clearer picture of the drug's actual effect (Simpson's paradox).\n",
    "\n",
    "This breaking down the population by its features is what we call **controlling for or conditioning on a variable $X$**. The treatment mechanism becomes as good as random by conditioning on the severe cases. \n",
    "\n",
    "Patients within the severe group may or may not receive the drug only due to chance, not due to a high severity anymore, since all patients are the same on this dimension. And if treatment is as if randomly assigned within groups, the treatment becomes conditionally independent of the potential outcomes. \n",
    "\n",
    "In a graphical model, each node is a random variable. We use arrows, or edges, to show if a variable causes another. The following graph shows the causal model for the impact of the medicine on patient survival. Severeness causes both medicine and survival, and medicine also causes survival. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00001-3eda73dd-4752-4173-ae9a-aee349a5fee3",
    "deepnote_cell_height": 243,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1988,
    "execution_start": 1647607228245,
    "source_hash": "43d4b80e",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz as gr\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00002-5d02a020-8733-4db1-b430-0f303774bba9",
    "deepnote_cell_height": 458,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     253
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 99,
    "execution_start": 1647607230242,
    "source_hash": "1fe929bf",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"136pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 135.64 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 131.64,-184 131.64,4 -4,4\"/>\n",
       "<!-- medicine -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>medicine</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"43.55\" cy=\"-90\" rx=\"43.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.55\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">medicine</text>\n",
       "</g>\n",
       "<!-- survived -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>survived</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"79.55\" cy=\"-18\" rx=\"40.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"79.55\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">survived</text>\n",
       "</g>\n",
       "<!-- medicine&#45;&gt;survived -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>medicine&#45;&gt;survived</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.26,-72.05C56.46,-63.89 61.59,-53.91 66.27,-44.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69.45,-46.28 70.91,-35.79 63.23,-43.08 69.45,-46.28\"/>\n",
       "</g>\n",
       "<!-- severeness -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>severeness</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"79.55\" cy=\"-162\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"79.55\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">severeness</text>\n",
       "</g>\n",
       "<!-- severeness&#45;&gt;medicine -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>severeness&#45;&gt;medicine</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.83,-144.05C66.63,-135.89 61.5,-125.91 56.83,-116.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"59.87,-115.08 52.18,-107.79 53.64,-118.28 59.87,-115.08\"/>\n",
       "</g>\n",
       "<!-- severeness&#45;&gt;survived -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>severeness&#45;&gt;survived</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.44,-144.14C90.25,-133.88 94.6,-120.41 96.55,-108 99.02,-92.19 99.02,-87.81 96.55,-72 95.17,-63.18 92.57,-53.82 89.81,-45.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.05,-44.13 86.44,-35.86 86.45,-46.45 93.05,-44.13\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc47bd47290>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "\n",
    "g.edge(\"medicine\", \"survived\")\n",
    "g.edge(\"severeness\", \"survived\")\n",
    "g.edge(\"severeness\", \"medicine\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-5eed9118-789c-4e7e-a339-28ea8453019c",
    "deepnote_cell_height": 234.34375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<br/><br/>\n",
    "## Basic Terminologies for Graphs\n",
    "\n",
    "\n",
    "For our purpose, it is (very) important that we understand what kind of independence and conditional independence assumptions a graphical model entails. To understand this, let's explain some common graphical definition and structures. They will be quite simple, but they are the sufficient building blocks to understand everything about graphical models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1d93add9-278d-4503-a633-2c0b39c78686",
    "deepnote_cell_height": 74.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Graph:** A graph $G = (V, E)$ is a set V of vertices (nodes) and a set E of edges, which can be graphically illustrated, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "700e0795-16b7-4991-9c8d-33feb26b930e",
    "deepnote_cell_height": 381,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     122
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 27,
    "execution_start": 1647607230350,
    "source_hash": "ec6e9c07",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'rankdir':'LR', 'label': \"A graph with nodes L , U , A  and Y​\"}, \n",
    "               node_attr={'shape': 'plaintext'}, \n",
    "               edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.edge(\"L\", \"U\", dir = \"none\")\n",
    "g.edge(\"L\", \"A\")\n",
    "g.edge(\"U\", \"A\")\n",
    "g.edge(\"A\", \"Y\")\n",
    "g\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b8d1e253-e1dc-46bf-b48c-c126e0f2b6ca",
    "deepnote_cell_height": 382.6875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Nodes:** typically represent random variables.\n",
    "\n",
    "**Edges (arrows):** can be undirected, directed or bi-directed and typically indicate a certain relationship between nodes or possible direct causal effects.\n",
    "\n",
    "**Path:** A trail of edges going from one node to another, not necessarily following the direction of arrows. a path cannot cross a node more than once.\n",
    "\n",
    "**Cyclic Graph:** A cyclic graph has at least one path that can be followed through directed edges back to the original node​\n",
    "\n",
    "**Acyclic Graph:** An acyclic graph is a graph that contains no such cycles.\n",
    "\n",
    "<br/><br/>\n",
    "**Example: Paths in a Graph**\n",
    "\n",
    "What are paths from X to C in the following graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6043cb7b-c4fd-4bd0-b069-35b9bc3aff93",
    "deepnote_cell_height": 518,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     187
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42,
    "execution_start": 1647607230380,
    "source_hash": "1abe9b0d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'rankdir':'LR'}, \n",
    "               edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"X\", \"X\", color=\"blue\", fontcolor=\"blue\")\n",
    "g.node(\"C\", \"C\", color=\"blue\", fontcolor=\"blue\")\n",
    "g.edge(\"U1\", \"Y\")\n",
    "g.edge(\"U1\", \"X\")\n",
    "g.edge(\"U2\", \"X\")\n",
    "g.edge(\"U2\", \"Y\")\n",
    "g.edge(\"X\", \"T\")\n",
    "g.edge(\"T\", \"C\")\n",
    "g.edge(\"C\", \"Y\")\n",
    "g.edge(\"X\", \"C\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "54c7d2fe-eaf9-400c-bedb-8e7dcf68b30c",
    "deepnote_cell_height": 153.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Paths from X to C are:\n",
    "\n",
    "- $ X \\rightarrow C$\n",
    "- $ X \\rightarrow T \\rightarrow C$\n",
    "- $ X \\rightarrow U_2 \\rightarrow Y \\rightarrow C$\n",
    "- $ X \\rightarrow U_1 \\rightarrow Y \\rightarrow C$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c2281eb1-f83b-4845-8672-1a0b63f181f0",
    "deepnote_cell_height": 242.734375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Directed Acyclic Graph (DAG):** A DAG is a graph that is both directed and acyclic.​\n",
    "\n",
    "**Children and Parents:** Nodes directly affected by and affecting other nodes respectively.​\n",
    "\n",
    "**Ancestors and Descendants:** Nodes directly or indirectly affected by and affecting other nodes\n",
    "\n",
    "**Exogenous and Endogenous Nodes:** Nodes without and with parents respectively​\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "**Example: Parents in a Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5fb1a843-4c68-4d0b-82a2-ff6b019f20c0",
    "deepnote_cell_height": 496,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     183
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 31,
    "execution_start": 1647607230430,
    "source_hash": "4a339dca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'rankdir':'LR'}, \n",
    "               edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"T\", \"T\", color=\"blue\", fontcolor=\"blue\")\n",
    "g.edge(\"U1\", \"Y\")\n",
    "g.edge(\"U1\", \"X\")\n",
    "g.edge(\"U2\", \"X\")\n",
    "g.edge(\"U2\", \"Y\")\n",
    "g.edge(\"X\", \"T\")\n",
    "g.edge(\"T\", \"C\")\n",
    "g.edge(\"C\", \"Y\")\n",
    "g.edge(\"X\", \"C\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7d209a97-7341-41a3-b9c6-7120508fa8a4",
    "deepnote_cell_height": 220.34375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Parents:** $pa(T) = \\{ X \\}$​\n",
    "\n",
    "**Children:** $ch(T) = \\{ C \\}$​\n",
    "\n",
    "**Ancestors:** $anc(T) = \\{ X, U_1, U_2 \\}$​\n",
    "\n",
    "**Descendants:** $desc(T) = \\{ C, Y \\}$​\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6d80e7a1-5653-4ab6-91bf-cd1087b94431",
    "deepnote_cell_height": 366.515625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## DAGs for Causal Inference \n",
    "\n",
    "DAGs as models are mathematical objects, part of a larger class of graphical models such as Bayesian networks or Markov networks.​ DAGs graphically represent *non-parametric structural equation models*.​\n",
    "\n",
    "- DAGs **advantages** for causal models:​\n",
    "\n",
    "    - All pictures, no algebra​\n",
    "\n",
    "    - Focus on causal links\n",
    "\n",
    "    - easy for deriving nonparametric analysis\n",
    "\n",
    "\n",
    "- DAGs **disadvantages** for causal models:​:\n",
    "\n",
    "    - Don’t display the parametric assumptions that are often necessary for estimation in practice.​\n",
    "\n",
    "    - Generality can obscure important distinctions between estimands.​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8df2870a-bc06-4b43-a1b2-ff68cf40ac5c",
    "deepnote_cell_height": 569.640625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Notes on Causal DAGs Assumptions\n",
    "\n",
    "- Causal DAGs encode the qualitative causal assumptions of the data-generating model *model of how the world works*. \n",
    "\n",
    "<br/>\n",
    "\n",
    "- Causal DAGs are **non-parametric**, i.e. they make no assumption about\n",
    "  - The distribution of the variables (nodes) in the DAG\n",
    "  - The functional form of the direct causal effects (arcs)\n",
    "\n",
    "<br/>\n",
    "\n",
    "- When we build a causal model (= drawing a DAG), we must consider all factors/variables that play a role in data generation, regardless of whether they are observed or unobserved.\n",
    "\n",
    "  - Causal assumptions are encoded by the *direction and absence of arrows*. \n",
    "  - *Directed arrows* or arcs represent possible direct causal effects.\n",
    "  - *Absence of arrows* or *missing arcs* represent sharp nulls of no-effect.\n",
    "\n",
    " <br/>\n",
    "  \n",
    "- Causal DAGs are **acyclic** because:\n",
    "\n",
    "    - One cannot trace a sequence of arcs in the direction of the arrows and arrive where one started.\n",
    "    - We impose acyclicness since a variable can’t cause itself.\n",
    "    - The future cannot directly or indirectly cause the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8c0aa1f9-9918-4115-a986-a6eb2b2dfab2",
    "deepnote_cell_height": 568,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     327
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 29,
    "execution_start": 1647607230471,
    "source_hash": "6a9af239",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph( graph_attr={'label': \"The arrow from A to B means that A may affect B, but not the other way around. \\n \" +\n",
    "                                    \"The absence of an arrow from D to B means that D does not affect B \\n\" + \n",
    "                                    \"The presence of C means that A and B may or may not have common causes.\"}, \n",
    "            edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.edge(\"C\", \"A\")\n",
    "g.edge(\"C\", \"B\")\n",
    "g.edge(\"A\", \"B\")\n",
    "g.node(\"D\", \"D\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a7b21d81-a9db-45be-96c0-1dd413e7a132",
    "deepnote_cell_height": 220.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### DAG Major Structure 1: Collider (V-Structure)\n",
    "\n",
    "- A collider (also known as v-structure or head-to-head meeting) has two incoming arrows along a chosen path.\n",
    "\n",
    "- A collider is when two arrows collide on a single variable. We can say that in this case both variables share a common effect.\n",
    "\n",
    "  $A \\!\\perp\\!\\!\\!\\perp B$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6e492bf8-59d9-4411-a4af-7eb818a663ef",
    "deepnote_cell_height": 338,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     187
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 27,
    "execution_start": 1647607230505,
    "source_hash": "4654047c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'label': \"A and B are independent in general\"}, edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.edge(\"A\", \"C\")\n",
    "g.edge(\"B\", \"C\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a8c0ed7c-3726-4c72-87ed-085e314a1219",
    "deepnote_cell_height": 175.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "- As a general rule, **conditioning (adjusting or controlling)** on a collider opens the causal path. Not conditioning on it leaves it closed.\n",
    "- This phenomenon is sometimes called **explaining away**, because one cause already explains the effect, making the other cause less likely.\n",
    "\n",
    "  $A \\not\\!\\perp\\!\\!\\!\\perp B | C$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7ba2e1f6-6b0b-4a64-84b0-706633364443",
    "deepnote_cell_height": 356.328125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     187.328125
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 88,
    "execution_start": 1647607230533,
    "source_hash": "653ea178",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'label': \"A and B are not independent anymore if we condition on C (collider)\"}, edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"C\", color=\"red\")\n",
    "g.edge(\"A\", \"C\")\n",
    "g.edge(\"B\", \"C\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "675df4cf-be04-42e2-b34f-fda20bc35764",
    "deepnote_cell_height": 128.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Example: 6 nodes graph** In the following graph: \n",
    "\n",
    "- $X$ is a collider on the path $U_1 \\rightarrow X \\leftarrow U_2$\n",
    "\n",
    "- $X$ is not a collider on the path $U_1 \\rightarrow X \\rightarrow T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0f6926ba-7b76-4045-8f0e-a4403ae659a1",
    "deepnote_cell_height": 467,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     154
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 59,
    "execution_start": 1647607230661,
    "source_hash": "296f7886",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'rankdir':'LR'}, \n",
    "               edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"X\", \"X\", color = \"blue\")\n",
    "g.edge(\"U1\", \"Y\")\n",
    "g.edge(\"U1\", \"X\")\n",
    "g.edge(\"U2\", \"X\")\n",
    "g.edge(\"U2\", \"Y\")\n",
    "g.edge(\"X\", \"T\")\n",
    "g.edge(\"T\", \"C\")\n",
    "g.edge(\"C\", \"Y\")\n",
    "g.edge(\"X\", \"C\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "555a0d36-6590-411c-b75a-7db6c1091fd2",
    "deepnote_cell_height": 295.90625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Example: School Admission**  \n",
    "\n",
    "We can assume there are two ways to be admitted to school. You can either be good at math or be good in arts. \n",
    "\n",
    "If you don't condition on the admission to school (i.e. you don't know if a student has been admitted to school), then being good in arts or maths are independent conditions. In other words, knowing that a student is good in math doens't tell anything about how good he is in arts (and viceversa). \n",
    "\n",
    "However, if you condition on the admission to school (i.e. you know the outcome of the admission), then being good in arts or maths become dependent. If you know that a student has been admitted to school and he is not talented in arts, then it is more likely that he is talented in math. Conversely, if he is bad at math but he has been admitted to school, then he has to be good in arts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1357fe37-c41d-415a-98ee-1092969c9ceb",
    "deepnote_cell_height": 361.65625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     156.65625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1647607230724,
    "source_hash": "7cadcc3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"A\", label=\"Talented in Arts\")\n",
    "g.node(\"B\", label=\"Talented in Math\")\n",
    "g.node(\"C\", label=\"Admitted to School\")\n",
    "g.edge(\"A\", \"C\")\n",
    "g.edge(\"B\", \"C\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Fire and Smoke Machine**  ** \n",
    "\n",
    "Intuitively we say that two variables are independent if knowing one variable doesn't provide any information on the other variable, i.e., it doesn't change our belief. \n",
    "Let's consider the following numerical example of a collider (similar to the previous example) where:\n",
    "\n",
    "- $P(F=1) = 0.2$\n",
    "- $P(M=1) = 0.1$\n",
    "- $P(S=1|F=0; M=0) = 0.1$\n",
    "- $P(S=1|F=1; M=0) = 0.8$\n",
    "- $P(S=1|F=0; M=1) = 0.8$\n",
    "- $P(S=1|F=1; M=1) = 0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.Digraph(edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"F\", label=\"Fire\")\n",
    "g.node(\"M\", label=\"Fog machine\")\n",
    "g.node(\"S\", label=\"Smoke\")\n",
    "g.edge(\"F\", \"S\")\n",
    "g.edge(\"M\", \"S\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we observe smoke ($S=1$), then the probability of fire increased to:\n",
    "\n",
    "$$P(F=1|S=1) = \\frac{P(S=1|F=1)P(F=1)}{P(S=1)} $$ \n",
    "where \n",
    "\\begin{align*}\n",
    "P(S=1) = P(S=1|F=0;M=0)P(F=0)P(M=0) +  \\\\\n",
    "            P(S=1|F=1;M=0)P(F=1)P(M=0) + \\\\           \n",
    "                P(S=1|F=0;M=1)P(F=0)P(M=1) + \\\\\n",
    "                    P(S=1|F=1;M=1)P(F=1)P(M=1)  \n",
    "\\end{align*}\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{align*}\n",
    "P(S=1|F=1) = P(S=1|F=1;M=0)P(M=0) +  \\\\\n",
    "            P(S=1|F=1;M=1)P(M=1)   \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "$P(F=1|S=1) = 0.54$\n",
    "\n",
    "However, if we observe that the fog machine is on, $M = 1$, then the probability of fire decreased to $P(F=1|S=1;M=1) = 0.22$.\n",
    "\n",
    "Here, $F$ and $M$ are not conditionally independent given $S$. When the probability of one explanation increases, the alternative explanations become less probable (they are explained away).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, we use **bnlearn** library in Python, [here](https://pypi.org/project/bnlearn/). The orginal library was first developemd for R by Marco Scutari. The package coime with a lot of examples. [Here](https://www.bnlearn.com) is the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnlearn as bn\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "# Define the network structure\n",
    "edges = [('Fire', 'Smoke'),\n",
    "         ('Machine', 'Smoke')]\n",
    "\n",
    "# Make the DAG\n",
    "DAG = bn.make_DAG(edges)\n",
    "\n",
    "cpt_fire = TabularCPD(variable='Fire', variable_card=2, values=[[0.8], [0.2]])\n",
    "cpt_machine = TabularCPD(variable='Machine', variable_card=2, values=[[0.9], [0.1]])\n",
    "\n",
    "\n",
    "cpt_smoke = TabularCPD(variable='Smoke', variable_card=2,\n",
    "                           values=[[0.9, 0.2, 0.2, 0.1],\n",
    "                                   [0.1, 0.8, 0.8, 0.9]],\n",
    "                           evidence=['Fire', 'Machine'],\n",
    "                           evidence_card=[2, 2])\n",
    "\n",
    "\n",
    "DAG = bn.make_DAG(DAG, CPD=[cpt_fire, cpt_machine, cpt_smoke])\n",
    "\n",
    "bn.print_CPD(DAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = bn.inference.fit(DAG, variables=['Fire'], evidence={'Smoke':1} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = bn.inference.fit(DAG, variables=['Fire'], evidence={'Smoke':1, 'Machine':1} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fbcc72d4-3cab-4585-9ddd-38f1d053a5ad",
    "deepnote_cell_height": 246.34375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### DAG Major Structure 2: Fork (Confounder)\n",
    "\n",
    "- A fork (or Confounder) is a node $C$ in a graph that has outgoing edges to two (or more) other variables $A$ and $B$.\n",
    "- Fork $C$ causes cofounding. Confounding means that $A$ and $B$ have a common cause (direct or indirect). \n",
    "- Fork $C$ is a common cause of $A$ and $B$. \n",
    "\n",
    "    $A \\not\\!\\perp\\!\\!\\!\\perp B$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "82dfd427-182a-4e5f-8609-64d898c9897c",
    "deepnote_cell_height": 338,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     187
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 112,
    "execution_start": 1647607230735,
    "source_hash": "7de0a144",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'label': \"A and B are not independent in general\"}, edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.edge(\"C\", \"A\")\n",
    "g.edge(\"C\", \"B\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "72d378b5-9d71-4ac0-9415-434d447b35d9",
    "deepnote_cell_height": 153.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "- In fork structure, the dependence flows backward through the arrows and we have what is called a **backdoor path**. \n",
    "- We can close the backdoor path and shut down dependence by conditioning on the common cause.\n",
    "\n",
    "    $A \\!\\perp\\!\\!\\!\\perp B | C$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2524faa8-029b-4ae0-93c6-dfeb1a6e5a75",
    "deepnote_cell_height": 356,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     187
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 29,
    "execution_start": 1647607230819,
    "source_hash": "ecbbe66d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'label': \"A and B are independent if we condition on C (fork)\"}, edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"C\", color=\"red\")\n",
    "g.edge(\"C\", \"A\")\n",
    "g.edge(\"C\", \"B\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "31bb0eba-6231-4887-a2a5-8ce5c0e720c6",
    "deepnote_cell_height": 214.734375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Example: Summer hot temperatures** \n",
    "\n",
    "We can consider the high temperature to influence the ice-cream consumption and number of solarburns. \n",
    "\n",
    "If you don't know whether it is summer (hot) or winter (cold), ice-cream consumption and number of solarburns are dependent (i.e., if we plot one w.r.t. the other we see a correlation). \n",
    "On the other hand, if we condition on the temperature (i.e. we know the temperature and if it is summer or winter), ice-cream consumption and number of solarburns become independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c028f19f-1383-498f-b35b-81983a5bbd35",
    "deepnote_cell_height": 361.65625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     156.65625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1647607230849,
    "source_hash": "ba398afe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"A\", label=\"Ice-cream consumption\")\n",
    "g.node(\"B\", label=\"Number of solarburns\")\n",
    "g.node(\"C\", label=\"Hot temperature\")\n",
    "g.edge(\"C\", \"A\")\n",
    "g.edge(\"C\", \"B\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [('Hot', 'Ice-cream'),\n",
    "         ('Hot', 'Solarburn')]\n",
    "\n",
    "# Make the actual Bayesian DAG\n",
    "DAG = bn.make_DAG(edges)\n",
    "\n",
    "cpt_icecream= TabularCPD(variable='Ice-cream', variable_card=2, values=[[0.7, 0.4],[0.3, 0.6]], evidence = ['Hot'], evidence_card=[2])\n",
    "cpt_solarburn = TabularCPD(variable='Solarburn', variable_card=2, values=[[0.9, 0.4],[0.1, 0.6]], evidence = ['Hot'], evidence_card=[2])\n",
    "\n",
    "cpt_hot = TabularCPD(variable='Hot', variable_card=2, values=[[0.5], [0.5]])\n",
    "\n",
    "DAG = bn.make_DAG(DAG, CPD=[cpt_icecream, cpt_solarburn, cpt_hot])\n",
    "bn.print_CPD(DAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = bn.inference.fit(DAG, variables=['Ice-cream'], evidence={'Hot':1} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = bn.inference.fit(DAG, variables=['Ice-cream'], evidence={'Solarburn':1, 'Hot':1} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b2906aa-7876-4dda-ac45-22969d03dca5",
    "deepnote_cell_height": 223.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### DAG Major Structure 3: Mediator (Chain)\n",
    "\n",
    "- A node $C$ is a mediator if it lies on a directed path from $A$ to $B$.\n",
    "- As a general rule, the dependence flow in the direct path from $A$ to $B$ is blocked when we condition on an intermediary variable $C$.\n",
    "\n",
    "  - $A \\not\\!\\perp\\!\\!\\!\\perp B$   \n",
    "\n",
    "  - $A \\!\\perp\\!\\!\\!\\perp B | C$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "85729589-2bf3-442c-9df9-281715064b9b",
    "deepnote_cell_height": 242,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     91
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25,
    "execution_start": 1647607230861,
    "source_hash": "5c2b13cd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'rankdir':'LR', 'label': \"A and B are not independent in general\"}, edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.edge(\"A\", \"C\")\n",
    "g.edge(\"C\", \"B\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6787d866-8a8d-45f9-a95a-e942277d8ff4",
    "deepnote_cell_height": 260,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     91
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1647607230936,
    "source_hash": "7ed516a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'rankdir':'LR', 'label': \"A and B are independent if we condition on C (mediator)\"}, edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"C\", color=\"red\")\n",
    "g.edge(\"A\", \"C\")\n",
    "g.edge(\"C\", \"B\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "276e7301-6b39-4b91-a204-73f6f5fa354b",
    "deepnote_cell_height": 192.34375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Example: Throwing Dices** \n",
    "\n",
    "Let's assume we are throwing dices. If we don't know (i.e. we don't condition) the sum in the first $n$ throws, then knowing the sum we got in the first $n-1$ throws helps us in better estimating the sum in the $n+1$ throws.\n",
    "\n",
    "However, if we condition (i.e. we observe) on the sum in the first $n$ throws, then knowing the sum in $n-1$ throws doesn't provide any information in better estimating the sum in $n+1$ thorws. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "10a98bed-eb72-473c-9926-58a11e04fe99",
    "deepnote_cell_height": 265.65625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     60.65625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 44,
    "execution_start": 1647607230937,
    "source_hash": "bd07b184",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'rankdir':'LR'}, edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"A\", label=\"Sum in n-1 throws\")\n",
    "g.node(\"B\", label=\"Sum in n throws\")\n",
    "g.node(\"C\", label=\"Sum in n+1 throws\")\n",
    "g.edge(\"A\", \"B\")\n",
    "g.edge(\"B\", \"C\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ef010c60-f187-4986-9e67-39064f583177",
    "deepnote_cell_height": 167.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## DAG Major Structure 4: Causal Paths\n",
    "\n",
    "A causal path is a route between two variables, following the direction of arrows. The causal path from $X$ to $C$ mediate the causal effect of $X$ on $C$, the non-causal path do not.\n",
    "\n",
    "For example in the graphs below, the causal path between $X$ and $C$ are highlighted in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "44b45d40-182e-4198-973b-7713b32a6a5b",
    "deepnote_cell_height": 518.328125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     187.328125
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 46,
    "execution_start": 1647607230980,
    "source_hash": "4714b6b4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(graph_attr={'rankdir':'LR'}, \n",
    "               edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.node(\"X\", \"X\", color = \"blue\")\n",
    "g.node(\"C\", \"C\", color = \"blue\")\n",
    "g.edge(\"U1\", \"Y\")\n",
    "g.edge(\"U1\", \"X\")\n",
    "g.edge(\"U2\", \"X\")\n",
    "g.edge(\"U2\", \"Y\")\n",
    "g.edge(\"X\", \"T\", color=\"red\")\n",
    "g.edge(\"T\", \"C\", color=\"red\")\n",
    "g.edge(\"C\", \"Y\")\n",
    "g.edge(\"X\", \"C\", color=\"red\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "da415130-cf58-4472-ba1c-6178dafb4e2a",
    "deepnote_cell_height": 220.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Path Blocking Rules\n",
    "\n",
    "Path are either open or blocked, according to two rules:\n",
    "\n",
    "- **Rule 1:** A path is blocked if somewhere along the path there is a variable $C$ that sits in a *chain*, or sits in a *fork* and we have conditioned for $C$. \n",
    "\n",
    "- **Rule 2:** A path is blocked if somewhere along the path there is a variable $C$ that sits in a *collider* and we have not conditioned for $C$, or any of its descendents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "23f2fe50-f8ac-45aa-b139-4dfe56232230",
    "deepnote_cell_height": 325.65625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     156.65625
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1647607231025,
    "source_hash": "5d0cf649",
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph(edge_attr={'arrowhead':'vee', 'arrowsize':'1'})\n",
    "g.edge(\"V\", \"A\")\n",
    "g.edge(\"V\", \"W\")\n",
    "g.edge(\"Y\", \"W\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1c2618ee-d6ae-4548-8f00-edb9129d6b10",
    "deepnote_cell_height": 178.953125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "From the causal graph above we notice that:\n",
    "- Conditioning for **V** blocks the path from **A** to **W** (rule 1) \n",
    "- Conditioning for **W** leaves the path open (rule 2) from **A** to **Y**. \n",
    "- Conditioning for both **V** and **W** blocks the path from **A** to **Y**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ee7eed8a-0f2d-4a90-854e-e41f889d7eff",
    "deepnote_cell_height": 919.96875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Path Blocking and D-Separation \n",
    "\n",
    "**d-separation in Sets:** Sets of variables $A$ and $B$ are d-separated (or blocked) by $C$ if all paths between $A$ and $B$ are blocked by $C$. d-separation implies: \n",
    "\n",
    "$A \\perp \\!\\!\\! \\perp B | C$.\n",
    "\n",
    "<br/>\n",
    "\n",
    "**d-separation in Paths:** D-separation determines which paths transmit association, and which ones don’t.\n",
    "Formally, a path **P** is said to be d-separated (or blocked) by a conditioning set of nodes $\\{Z\\}$ if:\n",
    "\n",
    "1. **P** contains a chain $A \\rightarrow M \\rightarrow B$ or a fork $A \\leftarrow M \\rightarrow B$ such that the middle node $M$ is in $\\{Z\\}$, or\n",
    "2. **P** contains a collider $A \\rightarrow M \\leftarrow B$ such that neither the middle node $M$, nor any descendant of $M$, is in $\\{Z\\}$.\n",
    "\n",
    "<br/>\n",
    "\n",
    "**d-connected in Paths:** A path **P** is said to be d-connected (or unblocked or open) by a conditioning set of nodes $\\{Z\\}$ if it is not d-separated.\n",
    "\n",
    "\n",
    "In other words:\n",
    "\n",
    "- *Blocked* (d-separated) paths don’t transmit association (information). \n",
    "\n",
    "- *Unblocked* (d-connected) paths may transmit association (information).\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "The three aforementioned blocking criteria can be rephased as: \n",
    "\n",
    "- Conditioning on a non-collider blocks a path, \n",
    "\n",
    "- Conditioning on a collider, or a descendent of a collider, unblocks a path, \n",
    "\n",
    "- Not conditioning on a collider leaves a path “naturally” blocked.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Path Blocking and Independence \n",
    "\n",
    "- Two variables that are d-separated along all paths given $\\{Z\\}$ are <font color='red'>conditionally independent given $\\{Z\\}$.</font>\n",
    "\n",
    "- Two variables that are *NOT* d-separated along all paths given $\\{Z\\}$ are <font color='red'>potentially dependent given $\\{Z\\}$.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3fac0589-db96-4209-94ab-d40c54166ecc",
    "deepnote_cell_height": 692.4375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Example for D-Separation \n",
    "\n",
    "We use the following DAG from [Bardy Neal course](https://www.bradyneal.com/causal-inference-course) to see blocked and un-blocked pathes between $T$ and $Y$ for different controlling (conditioning) cases.\n",
    "\n",
    "![img](img/ch3/graph_Dsep_example_case0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bc3a6faa-d562-40c2-ab40-fe7d13c26e47",
    "deepnote_cell_height": 658.828125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "**Case 1:** In the following graph, is  $T \\perp \\!\\!\\! \\perp Y | M_1$  valid?\n",
    "\n",
    "![img](img/ch3/graph_Dsep_example_case1.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "29d387ba-5c77-441b-97e3-0689ad6f9c7b",
    "deepnote_cell_height": 153.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**NO!**, \n",
    "- the chain path $T-M_1-M_2-Y$ is blocked ($M_1$ is in the conditioning set) \n",
    "- the fork path $T-W_1-W_2-W_3-Y$ is not blocked.\n",
    "- the collider path $T-X_1-X_2-X_3-Y$ is blocked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "863ba0fb-b574-4e95-af15-dd183d2b14bc",
    "deepnote_cell_height": 658.828125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "**Case 2:** In the following graph, is  $T \\perp \\!\\!\\! \\perp Y | M_1, W_2 $  valid?  \n",
    "\n",
    "![img](img/ch3/graph_Dsep_example_case2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8e4cb192-65a1-4bd4-ad8b-19ccf11332e9",
    "deepnote_cell_height": 153.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**YES!**, \n",
    "- the chain path $T-M_1-M_2-Y$ is blocked ($M_1$ is in the conditioning set) \n",
    "- the fork path $T-W_1-W_2-W_3-Y$ is blocked ($W_2$ is in the conditioning set).\n",
    "- the collider path $T-X_1-X_2-X_3-Y$ is blocked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00046-4464fcaa-1ecc-4156-8f88-d03800a3e4e1",
    "deepnote_cell_height": 658.828125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "**Case 3:** In the following graph, is  $T \\perp \\!\\!\\! \\perp Y | M_1, W_3 $  valid?  \n",
    "\n",
    "![img](img/ch3/graph_Dsep_example_case3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fe2c3d7b-98da-4d90-9d22-f628615f267f",
    "deepnote_cell_height": 153.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**YES!**,\n",
    "- the chain path $T-M_1-M_2-Y$ is blocked ($M_1$ is in the conditioning set). \n",
    "- the fork path $T-W_1-W_2-W_3-Y$ is blocked ($W_3$ is in the conditioning set).\n",
    "- the collider path $T-X_1-X_2-X_3-Y$ is blocked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00048-33acc8f8-091f-4f6e-b0d5-ca95a6517273",
    "deepnote_cell_height": 658.828125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "**Case 4:** In the following graph, is  $T \\perp \\!\\!\\! \\perp Y | M_1, W_1, W_2, X_2$  valid?  \n",
    "\n",
    "![img](img/ch3/graph_Dsep_example_case4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6a65db51-6e07-478d-a661-1e222610cfb8",
    "deepnote_cell_height": 153.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**NO!**,\n",
    "- the chain path $T-M_1-M_2-Y$ is blocked ($M_1$ is in the conditioning set). \n",
    "- the fork path $T-W_1-W_2-W_3-Y$ is blocked ($W_2, W_3$ are in the conditioning set).\n",
    "- the collider path $T-X_1-X_2-X_3-Y$ is NOT blocked ($X_2$ is in the conditioning set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4030a3d2-522a-4a33-ac83-e11de02542c7",
    "deepnote_cell_height": 658.828125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "**Case 5:** In the following graph, is  $T \\perp \\!\\!\\! \\perp Y | M_1, W_2, W_3, X_1, X_2?$  valid?\n",
    "\n",
    "![img](img/ch3/graph_Dsep_example_case5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00054-160f1856-1d83-45c9-8fd1-90fe514afd87",
    "deepnote_cell_height": 153.5625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**YES!**,\n",
    "- the chain path $T-M_1-M_2-Y$ is blocked ($M_1$ is in the conditioning set). \n",
    "- the fork path $T-W_1-W_2-W_3-Y$ is blocked ($W_2, W_3$ are in the conditioning set).\n",
    "- the collider path $T-X_1-X_2-X_3-Y$ is blocked ($X_1$ is in the conditioning set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Assumptions\n",
    "\n",
    "Causal DAGs need additional assumptions to be useful. These assumptions narrow down the possible solutions and hopefully makes the problem solvable. \n",
    "\n",
    "There are four common assumptions made across causal discovery algorithms. \n",
    "\n",
    " 1) **Acyclicity** — causal structure can be represented by a DAG $\\mathcal{G}$. We already seen that.\n",
    "\n",
    " 2) **Markov Property** — all nodes are independent of their non-descendants when conditioned on their parents. \n",
    "\n",
    " 3) **Faithfulness** — all conditional independences in true underlying distribution $p$ are represented in $\\mathcal{G}$ \n",
    "\n",
    " 4) **Sufficiency** — any pair of nodes in $\\mathcal{G}$ has no common external cause.\n",
    "\n",
    "<br/>\n",
    "\n",
    "A comprehensive discussion of these causal assumptions is availabe  in [Kalainathan et al., 2018]( https://arxiv.org/abs/1803.04929)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9abab6e8-564d-408b-a29d-aa0e1b64f25c",
    "deepnote_cell_height": 1409.8125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Markov Property\n",
    "### Definition of Markov Property\n",
    "\n",
    "\n",
    "- **When a distribution $p$ is Markovian with respect to a graph $\\mathcal{G}$, this graph encodes certain independence in the distribution.** \n",
    "\n",
    "- Markov property links causal DAGs to conditional probabilities (from data).\n",
    "\n",
    "We use two basic definitions before explaining Markov property:\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Chain Rule:** We know from the definition of conditional probability that: \n",
    "\n",
    "$$P(X_1,X_2) = P(X_1|X_2) \\cdot P(X_2) = P(X_2|X_1) \\cdot P(X_1)$$\n",
    "\n",
    "This can be generalied to multiple events (random variables): \n",
    "\n",
    "$$\n",
    "\\mathrm{P}\\left(X_n, \\ldots, X_1\\right) = \\mathrm{P}\\left(X_n \\mid X_{n-1}, \\ldots, X_1\\right) \\cdot \\mathrm{P}\\left(X_{n-1}, \\ldots, X_1\\right)\n",
    "$$\n",
    "\n",
    "Repeating this process with each final term creates the product form:\n",
    "\n",
    "$$\n",
    "\\mathrm{P}\\left(X_n, \\ldots, X_1\\right) = \\mathrm{P}\\left(\\bigcap_{k=1}^n X_k\\right) = \\prod_{k-1}^n \\mathrm{P}\\left(X_k \\mid \\bigcap_{j=1}^{k-1} X_j\\right)\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Conditional Independence:** Now let's $X,Y,Z$ be three random variables.\n",
    "\n",
    "- $X$ and $Y$ *are (marginally) independent* if: \n",
    "\n",
    "$$X \\perp Y \\Leftrightarrow  P(X,Y) = P(X) \\cdot P(Y)$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "- $X$ and $Y$ *are conditionally independent* if: \n",
    "\n",
    "$$X \\perp Y|Z \\Leftrightarrow  P(X, Y| Z) = P(X|Z) \\cdot P(Y|Z)$$ \n",
    "\n",
    "<br/>\n",
    "\n",
    "- Conditional Independence mathematically is equivalent to the statement that: *the joint distribution of the variables $X = \\{ X_1 , X_2 , ..., X_n \\}$ in a DAG $\\mathcal{G}$ can be factorized using the Markov factorization or Bayesian Network Factorization given parents $pa$ of ecah variable*:\n",
    "\n",
    "$$P(X) = \\prod_{i=1}^n P(X_i|pa(X_i))$$\n",
    "\n",
    "- In other words:\n",
    "    - Conditional on its parents, a variable $X_i$ is independent of its predecessors variables (conditional independence). \n",
    "    - Parents of $X_i$  or $pa(X_i)$ are independent aspects of the mechanism that generated $X_i$ values (data).  \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Definition 3.1 (Markov Property):** Given a DAG $\\mathcal{G}$ and a joint distribution $P_X$, this distribution is said to satisfy:\n",
    "\n",
    "<br/>\n",
    "\n",
    "(a) the **global Markov property** with respect to the DAG $\\mathcal{G}$ if:\n",
    "\n",
    "$$\\mathbf{A} \\!\\perp\\!\\!\\!\\perp_{\\mathcal{G}} \\mathbf{B}|\\mathbf{C} \\Rightarrow \\mathbf{A} \\!\\perp\\!\\!\\!\\perp \\mathbf{B}|\\mathbf{C}$$\n",
    "\n",
    "\n",
    "for all disjoint vertex sets $A,B,C$, the symbol $\\!\\perp\\!\\!\\!\\perp_{\\mathcal{G}}$ denotes d-separation.\n",
    "\n",
    "<br/>\n",
    "\n",
    "(b) the **local Markov property** with respect to the DAG $\\mathcal{G}$ if each variable is independent of its predecessors given its parents, and\n",
    "\n",
    "<br/>\n",
    "\n",
    "(c) the **Markov factorization property** with respect to the DAG $\\mathcal{G}$ if\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x})=p\\left(x_{1}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} p\\left(x_{i} \\mid \\mathbf{p} \\mathbf{a}_{i}^{\\mathcal{G}}\\right)\n",
    "$$\n",
    "\n",
    "For this last property, we have to assume that $P_X$ has a density $p$; the factors in the product are referred to as causal Markov kernels describing the conditional distributions $P_{X_{i} \\mid \\mathbf{PA}_{i}^{\\mathcal{G}}}$\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "54f765eb-c4eb-493b-b350-612ac81f4622",
    "deepnote_cell_height": 462.703125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Truncated Factorization\n",
    "\n",
    "An extension to Markov factorization is that the probability distribution generated by an intervention. For example, $do( X_1 = x_1 )$ is given by a Truncated Factorization:\n",
    "\n",
    "$$P(X_2, \\dots, X_n |do(X_1 = x_1)) = \\prod_{i \\neq 1} P(X_i | pa(X_i))$$\n",
    "\n",
    "**Truncated Factorization** suggested by (Pearl, 1993) is also known as the **G-formula** (Robins, 1986), or **manipulation theorem** (Spirtes, 2000), or **intervention formula** (Lauritzen, 2002).\n",
    "\n",
    "We have $X = \\{ X_1, X_2 , X_3 , ..., X_n \\}$, the causal effect of $X_1$ on $X_2$ can now be derived by marginalizing (summing) the truncated factorization over $X' = \\{ X_3 , ..., X_n \\}$:\n",
    "\n",
    "$$P(X_2|do(X_1=x_1)) = \\sum_{x'} P(X_2, X'|do(X_1=x_1))$$\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "See an example in this short [video](https://www.youtube.com/watch?v=_gcmY5ukbWM) made by [Brady Neal](https://www.bradyneal.com/causal-inference-course).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b9976685-062a-4fb5-b76d-1b6947285f40",
    "deepnote_cell_height": 100.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Local Markov Assumption in a Graph\n",
    "\n",
    "Given its parents in the DAG, a node $X$ is independent of all its predecessors. For example, let consider the graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "f4624bf1-16eb-4d02-8152-4e8b4cc0287c",
    "deepnote_cell_height": 386.328125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     199.328125
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1647607468720,
    "source_hash": "974d7484",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"251pt\" height=\"148pt\"\n",
       " viewBox=\"0.00 0.00 251.24 148.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 144.2)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-144.2 247.24,-144.2 247.24,4 -4,4\"/>\n",
       "<!-- X1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">X1</text>\n",
       "</g>\n",
       "<!-- X2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>X2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-122.2\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-118.5\" font-family=\"Times,serif\" font-size=\"14.00\">X2</text>\n",
       "</g>\n",
       "<!-- X1&#45;&gt;X2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X1&#45;&gt;X2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-36.15C27,-52.04 27,-75.39 27,-93.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"27,-103.91 22.5,-93.91 27,-98.91 27,-93.91 27,-93.91 27,-93.91 27,-98.91 31.5,-93.91 27,-103.91 27,-103.91\"/>\n",
       "</g>\n",
       "<!-- X3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"117.24\" cy=\"-70.1\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"117.24\" y=\"-66.4\" font-family=\"Times,serif\" font-size=\"14.00\">X3</text>\n",
       "</g>\n",
       "<!-- X1&#45;&gt;X3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>X1&#45;&gt;X3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.48,-29.82C59.39,-36.7 74.61,-45.49 87.8,-53.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"96.53,-58.14 85.62,-57.04 92.2,-55.64 87.87,-53.14 87.87,-53.14 87.87,-53.14 92.2,-55.64 90.12,-49.25 96.53,-58.14 96.53,-58.14\"/>\n",
       "</g>\n",
       "<!-- X2&#45;&gt;X3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X2&#45;&gt;X3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.48,-110.38C59.39,-103.5 74.61,-94.71 87.8,-87.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"96.53,-82.06 90.12,-90.95 92.2,-84.56 87.87,-87.06 87.87,-87.06 87.87,-87.06 92.2,-84.56 85.62,-83.16 96.53,-82.06 96.53,-82.06\"/>\n",
       "</g>\n",
       "<!-- X4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>X4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"216.24\" cy=\"-70.1\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.24\" y=\"-66.4\" font-family=\"Times,serif\" font-size=\"14.00\">X4</text>\n",
       "</g>\n",
       "<!-- X3&#45;&gt;X4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>X3&#45;&gt;X4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.29,-70.1C154.99,-70.1 167.46,-70.1 178.98,-70.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.22,-70.1 179.22,-74.6 184.22,-70.1 179.22,-70.1 179.22,-70.1 179.22,-70.1 184.22,-70.1 179.22,-65.6 189.22,-70.1 189.22,-70.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc47b945510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=gr.Digraph(edge_attr={'arrowhead':'vee', 'arrowsize':'1'}, graph_attr={'rankdir': 'LR', 'layout':'circo'})\n",
    "g.edge(\"X1\", \"X2\")\n",
    "g.edge(\"X1\", \"X3\")\n",
    "g.edge(\"X2\", \"X3\")\n",
    "g.edge(\"X3\", \"X4\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "47b98605-f268-4c0d-ac7d-3560d21b445d",
    "deepnote_cell_height": 146.265625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "In the graph above, we have:\n",
    "\n",
    "$$\n",
    "P(x_1, x_2, x_3, x_4) = P(x_1) P(x_2|x_1) P(x_3| x_2,x_1) P(x_4 | x_3, x_2, x_1)\n",
    "$$\n",
    "\n",
    "What happens with the *Local Markov Assumption*?\n",
    "\n",
    "$$\n",
    "P(x_1, x_2, x_3, x_4) = P(x_1) P(x_2|x_1) P(x_3| x_2,x_1) \\underbrace{P(x_4 | x_3, x_2, x_1)}_{P(x_4 | x_3)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "064b5dc8-e8c5-4c7b-849f-c265910030aa",
    "deepnote_cell_height": 1565.796875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### D-separation vs. Conditional independence\n",
    "\n",
    "We saw that DAGs offer an efficient (and visually easier) way to factorize the joint probability between random variables.\n",
    "We present here a summary of the cases we presented:\n",
    "\n",
    "- $A$ and $B$ are **marginally dependent**  ($A \\not \\perp B$)\n",
    " $$P(A,B) \\neq P(A) \\cdot P(B)$$\n",
    "![img](img/ch3/DAGs_PDFs_marginallyDep.png)\n",
    "\n",
    "- $A$ and $B$ are **marginally independent**  ($A \\perp B$)\n",
    " $$P(A,B) = P(A) \\cdot P(B)$$\n",
    "![img](img/ch3/DAGs_PDFs_marginallyIndep.png)\n",
    "\n",
    "\n",
    "- $A$ and $B$ are **conditionally independent given $C$**  ($A \\perp B | C$)\n",
    " $$P(A,B|C) = P(A|C) \\cdot P(B|C)$$\n",
    "![img](img/ch3/DAGs_PDFs_conditionallyIndep.png)\n",
    "\n",
    "\n",
    "- $A$ and $B$ are **conditionally dependent given $C$**  ($A \\not \\perp B | C$)\n",
    " $$P(A,B|C) \\neq P(A|C) \\cdot P(B|C)$$\n",
    "![img](img/ch3/DAGs_PDFs_conditionallyDep.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5af83390-7f1e-4134-a627-da1c3865e09d",
    "deepnote_cell_height": 265.125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Two (sets of) nodes $X$ and $Y$ are d-separated by a set of nodes $\\{Z\\}$ if all the paths between (any node in) $X$ and (any node in) $Y$ are blocked by $\\{Z\\}$. \n",
    "d-separation implies independence. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Theorem 3.2. (Global Markov Assumption):** Given that distribution $P$ is Markov with respect to graph $\\mathcal{G}$, d-separation in a graph $\\mathcal{G}$ is equivalent of conditional independent in distribution $P$. This is also called *Global Markov assumption*.\n",
    "\n",
    "$X \\!\\perp\\!\\!\\!\\perp_G Y |\\{Z\\} \\Rightarrow X \\!\\perp\\!\\!\\!\\perp_P Y |\\{Z\\}$\n",
    "\n",
    "Because of d-separation, we can read it $P$ is Markov with respect to $\\mathcal{G}$ or $P$ satisfy Markov assumption in respect to $\\mathcal{G}$.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d0ccc148-b2b7-4728-934e-793d36cc2831",
    "deepnote_cell_height": 1144.9375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Markov Equivalence\n",
    "\n",
    "We saw that chains and forks seem to encode the same independencies. They seem to be, in some way, equivalent to each other. We formalize here this concept.\n",
    "\n",
    "First, we introduce two important graph qualities that we can use to distinguish equivalent graphs: \n",
    "\n",
    "- **Skeleton:** an undirected graph obtained by removing directions \n",
    "\n",
    "- **Immorality (v-structure or collider):** a collider structure A → C ← B, such that there is no direct edge between A and B \n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Definition 3.3. (Markov Equivalence of Graphs)):** We denote by $\\mathcal{M}(\\mathcal{G})$ the set of distributions that are Markovian with respect to $\\mathcal{G}$ :\n",
    "\n",
    "$\\mathcal{M}(\\mathcal{G})$ = {$P$ : $P$ satisfies the global (or local) Markov property with respect to $\\mathcal{G}$}.\n",
    "\n",
    "Two DAGs $\\mathcal{G_1}$ and $\\mathcal{G_2}$ are **Markov equivalent** if $\\mathcal{M}(\\mathcal{G_1})$ = $\\mathcal{M}(\\mathcal{G_2})$. \n",
    "\n",
    "* This is the case if and only if $\\mathcal{G_1}$ and $\\mathcal{G_2}$ satisfy the same set of d-separations, which means the Markov condition entails the same set of (conditional) independence conditions.\n",
    "* The set of all DAGs that are Markov equivalent to the same distribution is called **Markov equivalence class of $\\mathcal{G}$**. \n",
    "\n",
    "</div>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Lemma 3.4. (Graphical criteria for Markov equivalence):** Two DAGs $\\mathcal{G_1}$ and $\\mathcal{G_2}$ are Markov equivalent if and only if they have the same skeleton and the same immoralities.\n",
    "\n",
    "   - Two graphs are Markov equivalent, if they entail the same conditional independencies. \n",
    "   - Two Markov equivalent graphs can be used for representing the same set of probability distributions.\n",
    "\n",
    "</div>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "Following figure shows an example of two Markov equivalent graphs.\n",
    "\n",
    "![img](img/ch3/Markov_equivalent.png)\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "See a short video on [Markov Equivalence](https://www.youtube.com/watch?v=nnjKCtdORwY&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=64) made by Brady Neal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d662b0f6-db9a-4355-be3f-3f234ddf3355",
    "deepnote_cell_height": 905.859375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Markov Blanket\n",
    "\n",
    "The **Markov blanket** of a node $X$, denoted by $MB(X)$, consists of the children, parents and spouses (parents of children) of $X$. \n",
    "- $MB(X)$ is a subset that contains all the useful information about $X$. \n",
    "- $X$ is conditionally independent of all nodes outside its Markov blanket given its Markov blanket:\n",
    "\n",
    "$X \\!\\perp\\!\\!\\!\\perp N \\setminus MB(X) | MB(X)$\n",
    "\n",
    "![img](img/ch3/Markov_blanket.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4a00d9983b664ea1a253163e6fb4991d",
    "deepnote_cell_height": 645.421875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Common Cause Principle\n",
    "\n",
    "So far, we have discussed the Markov property as the connecting factor for distributions and graphs. Now, we discuss some of its causal implications. \n",
    "\n",
    "We can use Markov property to justify **Reichenbach’s Common Cause Principle**. It states that when the random variables $X$ and $Y$ are dependent, there must be a *causal explanation* for this dependence:\n",
    "\n",
    "- $X$ is (possibly indirectly) causing $Y$, or \n",
    "- $Y$ is (possibly indirectly) causing $X$, or\n",
    "- there is a (possibly unobserved) common cause $Z$ that (possibly indirectly) causes both $X$ and $Y$.\n",
    "\n",
    "The following proposition justifies Reichenbach’s principle with respect to a notion of “causing,” namely the existence of a directed path.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Proposition 3.5. (Reichenbach’s Common Cause Principle):** Assume that any pair of variables $X$ and $Y$ can be embedded into a larger system in the following sense. There exists a **causal model** over the collection $\\mathbf{X}$ of random variables that contains $X$ and $Y$ within graph $\\mathcal{G}$. Then Reichenbach’s common cause principle follows from the Markov property. If $X$ and $Y$ are dependent, then there is:\n",
    "\n",
    "<br/>\n",
    "\n",
    "- either a directed path from $X$ to $Y$ , or \n",
    "\n",
    "<br/>\n",
    "\n",
    "- a directed path from $Y$ to $X$,or \n",
    "\n",
    "<br/>\n",
    "\n",
    "- there is a node $Z$ with a directed path from $Z$ to $X$ and from $Z$ to $Y$.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4851617257fe4ddd9d90faa06023646f",
    "deepnote_cell_height": 931.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Causal Graphical Models\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Proposition 3.6. (Causal Model vs. Markov Property):** [Source](https://mitpress.mit.edu/books/elements-causal-inference) Assume that $P_X$ is induced by an Structural causal Model (SCM) with graph $\\mathcal{G}$. Then, $P_X$ is Markovian with respect to $\\mathcal{G}$. The assumption that says a distribution is Markovian with respect to the causal graph is sometimes called the **causal Markov condition**. \n",
    "\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "We will see in the next chapter that it is sufficient to know the observational data distribution and the related graph structure for defining intervention distributions for a process. Therefore, we define a causal graphical model as a pair consisting of a *graph* and an *observational distribution* such that the distribution is Markovian with respect to the graph (causal Markov condition).\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Definition 3.7 (Causal graphical model):** A causal graphical model over random variables $\\mathbf{X}=\\left(X_{1}, \\ldots, X_{d}\\right)$ contains a graph $\\mathcal{G}$ and a collection of functions $f_{j}\\left(x_{j}, x_{\\mathbf{P A}_{j}^{\\mathcal{G}}}\\right)$ that integrate to $1:$\n",
    "\n",
    "$$\n",
    "\\int f_{j}\\left(x_{j}, x_{\\mathbf{P A}_{j}^{\\mathcal{G}}}\\right) d x_{j}=1\n",
    "$$\n",
    "\n",
    "These collection (structure) of functions induces a distribution $P_{\\mathbf{X}}$ over $\\mathbf{X}$ via\n",
    "\n",
    "$$\n",
    "p\\left(x_{1}, \\ldots, x_{d}\\right)=\\prod_{j=1}^{d} f_{j}\\left(x_{j}, x_{\\mathbf{PA_j}}^{\\mathcal{G}}\\right)\n",
    "$$\n",
    "\n",
    "and thus play the role of conditionals: \n",
    "\n",
    "$$\n",
    "f_{j}\\left(x_{j}, x_{\\mathbf{PA_j^\\mathcal{G}}}\\right) = p\\left(x_{j} \\mid x_{\\mathbf{PA_j}^\\mathcal{G}}\\right)\n",
    "$$\n",
    "\n",
    "Refer to [Causal Elements Book, Chapter 6](https://mitpress.mit.edu/books/elements-causal-inference) for proof.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "If a distribution $P_X$ over $X$ is Markovian with respect to a graph $\\mathcal{G}$ and allows for a strictly positive, continuous density $p$, the pair $(P_X,\\mathcal{G})$ defines a **causal graphical model** by:\n",
    "\n",
    "$$\n",
    "f_j\\left(x_{j} \\mid x_{\\mathbf{PA_j}^\\mathcal{G}}\\right) = p\\left(x_{j} \\mid x_{\\mathbf{PA_j}^\\mathcal{G}}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "See a short video on [Causal Graphs](https://www.youtube.com/watch?v=vjvP9oRgZyM&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=21) made by Brady Neal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faithfulness and Causal Minimality\n",
    "\n",
    "\n",
    "As we seen, the **Markov** assumption enables us to undrestand **independences** from a graph structure. **Faithfulness** allows us to infer **dependences** from the graph structure.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Definition 3.8 (Faithfulness and causal minimality):** Consider a distribution $P_\\mathbf{X}$ and a DAG $\\mathcal{G}$.\n",
    "    \n",
    "**(a)** $P_\\mathbf{X}$ is faithfulls to DAG $\\mathcal{G}$ if\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\!\\perp\\!\\!\\!\\perp \\mathbf{B}\\left|\\mathbf{C} \\Rightarrow \\mathbf{A} \\!\\perp\\!\\!\\!\\perp_{\\mathcal{G}} \\mathbf{B}\\right| \\mathbf{C}\n",
    "$$\n",
    "\n",
    "for all  all disjoint vertex sets $\\mathbf{A}, \\mathbf{B}, \\mathbf{C}$.\n",
    "\n",
    "**(b)** A distribution satisfies causal minimality with respect to $\\mathcal{G}$ if it is Markovian with respect to $\\mathcal{G}$, but not to any proper subgraph of $\\mathcal{G}$.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Part (a) posits an implication that is the opposite of the global Markov condition:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\!\\perp\\!\\!\\!\\perp_{\\mathcal{G}} \\mathbf{B}|\\mathbf{C} \\Rightarrow \\mathbf{A} \\!\\perp\\!\\!\\!\\perp \\mathbf{B}| \\mathbf{C},\n",
    "$$\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Proposition 3.9 (Faithfulness implies causal minimality):** If $P_\\mathbf{X}$ is faithful and Markovian with respect to $\\mathcal{G}$, then causal minimality is satisfied.\n",
    "    \n",
    "</div>\n",
    "\n",
    "A distribution is minimal with respect to $\\mathcal{G}$ if and only if there is no node that is conditionally independent of any of its parents, given the remaining parents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass\n",
    "\n",
    "## Interventional Sufficiency\n",
    "\n",
    "A set of variables $P_\\mathbf{X}$ is usually said to be **causally sufficient** if there is no hidden common cause $C \\notin \\mathbf{X}$ that is causing more than one variable in $\\mathbf{X}$.\n",
    "\n",
    "- The definition **causally sufficient** matches the intuitive meaning of the set of “relevant” variables. However, it uses the concept of a **common cause** and should therefore be understood relative to a larger set of variables $\\tilde{\\mathbf{X}} \\supseteq \\mathbf{X}$.\n",
    "\n",
    "- In the structural causal model corresponding to this larger set $\\tilde{\\mathbf{X}}$ , a variable $C$ is a **common cause** of $X$ and $Y$ if there is a directed path from $C$ to $X$ and $Y$ that does not include $Y$ and $X$, respectively.\n",
    "\n",
    "- **Common causes** are also called **confounders** and we use these terms interchangeably.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Definition 3.10 (Interventional sufficiency):** We call a set $\\mathbf{X}$ of variables interventionally sufficient if there exists an SCM over $\\mathbf{X}$ that cannot be falsified as an interventional model. It also induces (create) observational and intervention distributions that coincide with what we observe in practice.\n",
    "\n",
    "</div>\n",
    "\n",
    "**Interventional sufficiency** describes when a set of variables is large enough to perform causal reasoning, in the sense of computing observational and intervention distributions.\n",
    "\n",
    "For more information on Interventional sufficiency, see Chapter 9. Hidden Variables from [Elements of Causal Inference](https://mitpress.mit.edu/books/elements-causal-inference) book.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **Note:** What we saw is part of the math under the hook! In this course, we are focused on using causal DAGs. However, DAGs can still be of great practical use without detailed knowledge of this mathematical background. If you want to know more in-depth math, see Judea Pearl's paper [Foundations of Causal Inference, 2010](https://ftp.cs.ucla.edu/pub/stat_ser/r355-reprint.pdf) and books we suggested in the syllabus. </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c9e7f5186c4545eca8adbf149c8ad029",
    "deepnote_cell_height": 167.171875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "This chapter contents are highly inspired by the [Elements of Causal Inference (Open Access) book](https://mitpress.mit.edu/books/elements-causal-inference) by By Jonas Peters, Dominik Janzing and [Bernhard Schölkopf](https://www.is.mpg.de/~bs) especially for definitions and propositions.\n",
    "\n",
    "We also used a graph example from the [Introduction to Causal Inference](https://www.bradyneal.com/causal-inference-course) course by Brady Neal. He made a very nice open-access online course accompanied by videos on [YouTube](https://youtube.com/playlist?list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0).\n",
    "\n",
    "More proofs and theores can ber find in Judea Pearl's [Causal Inference in Statistics: A Primer](https://www.wiley.com/en-us/Causal+Inference+in+Statistics%3A+A+Primer-p-9781119186847).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "09b16480-942c-492c-be08-da138720dcc2",
  "interpreter": {
   "hash": "f82454df3ab4669350e470cecfad51160e6fdff8e76eafd19d8880dd92d922a3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
